#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìˆ˜ì •ëœ ì „ì²´ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (ìŠ¤í‚¤ë§ˆ í˜¸í™˜ ë²„ì „)
ê¸°ì¡´ news_articles í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
"""

import sys
import os
import argparse
import sqlite3
import requests
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
import logging
import time
from urllib.parse import quote
from dotenv import load_dotenv
import traceback

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class FixedCompanyNewsCollector:
    """ìˆ˜ì •ëœ ì „ì²´ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    
    def __init__(self, delay=0.2, batch_size=50):
        # ë„¤ì´ë²„ API ì„¤ì •
        self.naver_client_id = os.getenv('NAVER_CLIENT_ID')
        self.naver_client_secret = os.getenv('NAVER_CLIENT_SECRET')
        
        if not self.naver_client_id or not self.naver_client_secret:
            raise ValueError("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        self.stock_db_path = Path('data/databases/stock_data.db')
        self.news_db_path = Path('data/databases/news_data.db')
        
        # ìˆ˜ì§‘ ì„¤ì •
        self.delay = delay
        self.batch_size = batch_size
        self.max_news_per_company = 100
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('news_collection_fixed.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ì§„í–‰ ìƒí™© ì¶”ì ìš© íŒŒì¼
        self.progress_file = Path('news_collection_progress_fixed.txt')
        
        # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ í™•ì¸ ë° ì„¤ì •
        self.available_columns = self.check_table_schema()
        
        # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
        self.financial_keywords = [
            'ì‹¤ì ', 'ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ë°°ë‹¹', 'íˆ¬ì', 'ì¸ìˆ˜í•©ë³‘', 'M&A',
            'ì‹ ì œí’ˆ', 'ì¶œì‹œ', 'ê³„ì•½', 'ìˆ˜ì£¼', 'íŠ¹í—ˆ', 'ê¸°ìˆ ê°œë°œ', 'ì—°êµ¬ê°œë°œ',
            'ì¦ì„¤', 'íˆ¬ì', 'ê³µì¥', 'ì‹œì„¤', 'ìƒì‚°', 'ê³µê¸‰', 'í™•ì¥',
            'ì£¼ê°€', 'ìƒìŠ¹', 'í•˜ë½', 'ëª©í‘œê°€', 'íˆ¬ìì˜ê²¬', 'ë§¤ìˆ˜', 'ë§¤ë„',
            'ë¶„í• ', 'í•©ë³‘', 'ìœ ìƒì¦ì', 'ë¬´ìƒì¦ì', 'ìì‚¬ì£¼', 'ë°°ë‹¹ê¸ˆ',
            'CEO', 'ëŒ€í‘œì´ì‚¬', 'ì„ì›', 'ì¸ì‚¬', 'ì¡°ì§ê°œí¸', 'ê²½ì˜ì§„',
            'ì—…ì ', 'ì„±ê³¼', 'ì „ë§', 'ê³„íš', 'ì „ëµ', 'ì‚¬ì—…', 'ë¶€ë¬¸'
        ]
        
        # ê°ì •ë¶„ì„ í‚¤ì›Œë“œ
        self.positive_words = [
            'ì„±ì¥', 'ì¦ê°€', 'ìƒìŠ¹', 'ê°œì„ ', 'í™•ëŒ€', 'í˜¸ì¡°', 'ì¢‹ì€', 'ê¸ì •', 'ì„±ê³µ',
            'ë‹¬ì„±', 'ëŒíŒŒ', 'ìµœê³ ', 'ìš°ìˆ˜', 'ê°•ì„¸', 'ê¸°ëŒ€', 'ì „ë§', 'í˜ì‹ '
        ]
        
        self.negative_words = [
            'ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”', 'ì¶•ì†Œ', 'ìš°ë ¤', 'ë‚˜ìœ', 'ë¶€ì •', 'ì‹¤íŒ¨',
            'ë¶€ì¡±', 'ì†ì‹¤', 'ì ì', 'ìµœì €', 'ë¶€ì‹¤', 'ë¶ˆì•ˆ', 'ìœ„í—˜', 'í•˜í–¥'
        ]
        
        # í†µê³„ ì¶”ì 
        self.stats = {
            'total_companies': 0,
            'processed_companies': 0,
            'successful_companies': 0,
            'total_news_collected': 0,
            'financial_news_saved': 0,
            'api_calls': 0,
            'errors': 0,
            'start_time': None
        }
    
    def check_table_schema(self):
        """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ í™•ì¸ ë° ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ë°˜í™˜"""
        try:
            with sqlite3.connect(self.news_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("PRAGMA table_info(news_articles)")
                columns = cursor.fetchall()
                
                column_names = [col[1] for col in columns]
                self.logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {column_names}")
                
                return column_names
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ í™•ì¸ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì»¬ëŸ¼ë“¤ ë°˜í™˜
            return ['stock_code', 'title', 'description', 'originallink', 'link', 
                   'pubDate', 'source', 'category', 'created_at']
    
    def get_insert_query_and_data(self, news_item, stock_code, company_name, sentiment):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ì— ë§ëŠ” INSERT ì¿¼ë¦¬ì™€ ë°ì´í„° ìƒì„±"""
        
        # ëª¨ë“  ê°€ëŠ¥í•œ ë°ì´í„° ì¤€ë¹„
        all_data = {
            'stock_code': stock_code,
            'company_name': company_name,  # ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            'title': re.sub(r'<[^>]+>', '', news_item.get('title', ''))[:500],
            'description': re.sub(r'<[^>]+>', '', news_item.get('description', ''))[:1000],
            'originallink': news_item.get('originallink', ''),
            'link': news_item.get('link', ''),
            'pubDate': news_item.get('pubDate', ''),
            'source': 'ë„¤ì´ë²„ë‰´ìŠ¤',
            'category': 'ê¸ˆìœµ',
            'sentiment_score': sentiment.get('sentiment_score', 0.0),
            'sentiment_label': sentiment.get('sentiment_label', 'neutral'),
            'confidence_score': sentiment.get('confidence', 0.0),
            'keywords': f"ê¸ì •:{sentiment.get('positive_count', 0)},ë¶€ì •:{sentiment.get('negative_count', 0)}",
            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_data = {}
        for col in self.available_columns:
            if col in all_data:
                available_data[col] = all_data[col]
        
        # INSERT ì¿¼ë¦¬ ìƒì„±
        columns_str = ', '.join(available_data.keys())
        placeholders = ', '.join(['?' for _ in available_data])
        query = f"INSERT INTO news_articles ({columns_str}) VALUES ({placeholders})"
        
        return query, list(available_data.values())
    
    def get_all_companies(self):
        """stock_data.dbì—ì„œ ëª¨ë“  íšŒì‚¬ ì •ë³´ ì¡°íšŒ"""
        try:
            if not self.stock_db_path.exists():
                raise FileNotFoundError("stock_data.db íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            with sqlite3.connect(self.stock_db_path) as conn:
                query = """
                    SELECT stock_code, company_name, market_cap, market_type
                    FROM company_info 
                    WHERE company_name IS NOT NULL 
                        AND company_name != ''
                        AND LENGTH(company_name) >= 2
                    ORDER BY 
                        CASE WHEN market_cap IS NOT NULL THEN market_cap ELSE 0 END DESC,
                        company_name
                """
                
                cursor = conn.execute(query)
                companies = cursor.fetchall()
                
                self.logger.info(f"ì „ì²´ íšŒì‚¬ ì¡°íšŒ ì™„ë£Œ: {len(companies)}ê°œ")
                return companies
                
        except Exception as e:
            self.logger.error(f"íšŒì‚¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def load_progress(self):
        """ì§„í–‰ ìƒí™© ë¡œë“œ"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        last_line = lines[-1].strip()
                        if ',' in last_line:
                            parts = last_line.split(',')
                            if len(parts) >= 2:
                                return int(parts[0]), parts[1]
                return 0, None
            except Exception as e:
                self.logger.warning(f"ì§„í–‰ ìƒí™© ë¡œë“œ ì‹¤íŒ¨: {e}")
                return 0, None
        return 0, None
    
    def save_progress(self, index, company_name, stock_code):
        """ì§„í–‰ ìƒí™© ì €ì¥"""
        try:
            with open(self.progress_file, 'a', encoding='utf-8') as f:
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                f.write(f"{index},{company_name},{stock_code},{timestamp}\n")
        except Exception as e:
            self.logger.warning(f"ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def search_company_news(self, company_name, max_results=100):
        """íŠ¹ì • íšŒì‚¬ì˜ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            headers = {
                'X-Naver-Client-Id': self.naver_client_id,
                'X-Naver-Client-Secret': self.naver_client_secret
            }
            
            all_news = []
            
            # íšŒì‚¬ëª… ê²€ìƒ‰
            search_queries = [
                f'"{company_name}"',  # ì •í™•í•œ íšŒì‚¬ëª…
                company_name,         # ì¼ë°˜ ê²€ìƒ‰
            ]
            
            for query in search_queries:
                for page in range(1, 4):  # ìµœëŒ€ 3í˜ì´ì§€
                    params = {
                        'query': query,
                        'display': 100,
                        'start': ((page - 1) * 100) + 1,
                        'sort': 'date'
                    }
                    
                    response = requests.get(self.base_url, headers=headers, params=params, timeout=30)
                    response.raise_for_status()
                    
                    self.stats['api_calls'] += 1
                    
                    data = response.json()
                    news_items = data.get('items', [])
                    
                    if not news_items:
                        break
                    
                    all_news.extend(news_items)
                    
                    if len(all_news) >= max_results:
                        break
                    
                    time.sleep(0.05)
                
                if len(all_news) >= max_results:
                    break
            
            # ì¤‘ë³µ ì œê±°
            unique_news = []
            seen_links = set()
            
            for news in all_news:
                link = news.get('link', '')
                if link and link not in seen_links:
                    unique_news.append(news)
                    seen_links.add(link)
            
            self.stats['total_news_collected'] += len(unique_news)
            return unique_news[:max_results]
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {company_name} - {e}")
            self.stats['errors'] += 1
            return []
    
    def filter_financial_news(self, news_items, company_name):
        """ê¸ˆìœµ ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§"""
        filtered_news = []
        
        for item in news_items:
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()
            content = f"{title} {description}"
            
            # HTML íƒœê·¸ ì œê±°
            content = re.sub(r'<[^>]+>', '', content)
            
            # íšŒì‚¬ëª… í¬í•¨ í™•ì¸
            company_variations = [
                company_name.lower(),
                company_name.replace('(ì£¼)', '').replace('ãˆœ', '').lower(),
                company_name.replace('ì£¼ì‹íšŒì‚¬', '').lower()
            ]
            
            company_mentioned = any(variation in content for variation in company_variations)
            
            if not company_mentioned:
                continue
            
            # ê¸ˆìœµ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
            financial_score = sum(1 for keyword in self.financial_keywords if keyword.lower() in content)
            
            if financial_score >= 1:
                filtered_news.append(item)
        
        return filtered_news
    
    def analyze_sentiment(self, text):
        """ê°ì •ë¶„ì„"""
        clean_text = re.sub(r'<[^>]+>', '', text).lower()
        
        positive_count = sum(1 for word in self.positive_words if word in clean_text)
        negative_count = sum(1 for word in self.negative_words if word in clean_text)
        
        total_words = positive_count + negative_count
        if total_words == 0:
            sentiment_score = 0.0
            confidence = 0.1
        else:
            sentiment_score = (positive_count - negative_count) / total_words
            confidence = min(total_words / 10, 1.0)
        
        if sentiment_score > 0.1:
            sentiment_label = 'positive'
        elif sentiment_score < -0.1:
            sentiment_label = 'negative'
        else:
            sentiment_label = 'neutral'
        
        return {
            'sentiment_score': sentiment_score,
            'sentiment_label': sentiment_label,
            'confidence': confidence,
            'positive_count': positive_count,
            'negative_count': negative_count
        }
    
    def save_news_to_db(self, news_items, stock_code, company_name):
        """ë‰´ìŠ¤ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ìŠ¤í‚¤ë§ˆ í˜¸í™˜)"""
        try:
            saved_count = 0
            
            with sqlite3.connect(self.news_db_path) as conn:
                for item in news_items:
                    try:
                        # ê°ì •ë¶„ì„
                        title = re.sub(r'<[^>]+>', '', item.get('title', ''))
                        description = re.sub(r'<[^>]+>', '', item.get('description', ''))
                        sentiment = self.analyze_sentiment(f"{title} {description}")
                        
                        # ì¤‘ë³µ í™•ì¸
                        existing = conn.execute(
                            "SELECT id FROM news_articles WHERE link = ?",
                            (item.get('link', ''),)
                        ).fetchone()
                        
                        if existing:
                            continue
                        
                        # ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ì¿¼ë¦¬ì™€ ë°ì´í„° ìƒì„±
                        query, data = self.get_insert_query_and_data(item, stock_code, company_name, sentiment)
                        
                        # ë°ì´í„° ì €ì¥
                        conn.execute(query, data)
                        saved_count += 1
                        
                    except sqlite3.Error as e:
                        self.logger.warning(f"ê°œë³„ ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
                        continue
                
                conn.commit()
            
            self.stats['financial_news_saved'] += saved_count
            return saved_count
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            self.stats['errors'] += 1
            return 0
    
    def print_progress(self, current, total, company_name, news_count=0):
        """ì§„í–‰ ìƒí™© ì¶œë ¥"""
        percentage = (current / total) * 100
        elapsed_time = time.time() - self.stats['start_time']
        
        if current > 0:
            avg_time_per_company = elapsed_time / current
            remaining_companies = total - current
            eta_seconds = avg_time_per_company * remaining_companies
            eta_str = str(timedelta(seconds=int(eta_seconds)))
        else:
            eta_str = "ê³„ì‚° ì¤‘..."
        
        print(f"\rì§„í–‰ë¥ : {current:,}/{total:,} ({percentage:.1f}%) | "
              f"í˜„ì¬: {company_name[:20]} | ë‰´ìŠ¤: {news_count}ê±´ | "
              f"ê²½ê³¼: {str(timedelta(seconds=int(elapsed_time)))} | "
              f"ì˜ˆìƒ ì™„ë£Œ: {eta_str}", end='', flush=True)
    
    def collect_all_company_news(self, resume=False):
        """ëª¨ë“  íšŒì‚¬ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        self.stats['start_time'] = time.time()
        
        # íšŒì‚¬ ëª©ë¡ ì¡°íšŒ
        companies = self.get_all_companies()
        if not companies:
            self.logger.error("ìˆ˜ì§‘í•  íšŒì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        self.stats['total_companies'] = len(companies)
        self.logger.info(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: {len(companies):,}ê°œ íšŒì‚¬")
        self.logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {self.available_columns}")
        
        # ì§„í–‰ ìƒí™© ë¡œë“œ
        start_index = 0
        if resume:
            start_index, last_company = self.load_progress()
            if start_index > 0:
                self.logger.info(f"ìˆ˜ì§‘ ì¬ê°œ: {start_index}ë²ˆì§¸ë¶€í„°")
        
        # íšŒì‚¬ë³„ ì²˜ë¦¬
        for i in range(start_index, len(companies)):
            stock_code, company_name, market_cap, market_type = companies[i]
            
            try:
                self.stats['processed_companies'] += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                self.print_progress(i + 1, len(companies), company_name)
                
                # ë‰´ìŠ¤ ê²€ìƒ‰
                news_items = self.search_company_news(company_name, self.max_news_per_company)
                
                if not news_items:
                    self.save_progress(i, company_name, stock_code)
                    continue
                
                # ê¸ˆìœµ ë‰´ìŠ¤ í•„í„°ë§
                filtered_news = self.filter_financial_news(news_items, company_name)
                
                if not filtered_news:
                    self.save_progress(i, company_name, stock_code)
                    continue
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                saved_count = self.save_news_to_db(filtered_news, stock_code, company_name)
                
                if saved_count > 0:
                    self.stats['successful_companies'] += 1
                
                self.save_progress(i, company_name, stock_code)
                time.sleep(self.delay)
                
                # ë°°ì¹˜ ë‹¨ìœ„ ë¡œê·¸
                if (i + 1) % self.batch_size == 0:
                    self.logger.info(f"\në°°ì¹˜ ì™„ë£Œ: {i + 1:,}/{len(companies):,} "
                                   f"(ì„±ê³µ: {self.stats['successful_companies']:,}, "
                                   f"ì €ì¥: {self.stats['financial_news_saved']:,}ê±´)")
                
            except KeyboardInterrupt:
                print(f"\n\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
                print(f"ğŸ“ ì¤‘ë‹¨ ì§€ì : {i + 1}/{len(companies)} - {company_name}")
                return False
                
            except Exception as e:
                self.logger.error(f"íšŒì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {company_name} - {e}")
                self.stats['errors'] += 1
                self.save_progress(i, company_name, stock_code)
                continue
        
        # ìµœì¢… í†µê³„
        elapsed_time = time.time() - self.stats['start_time']
        print(f"\n\n{'='*80}")
        print(f"ğŸ“Š ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ¢ ì „ì²´ íšŒì‚¬: {self.stats['total_companies']:,}ê°œ")
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {self.stats['processed_companies']:,}ê°œ")  
        print(f"ğŸ¯ ìˆ˜ì§‘ ì„±ê³µ: {self.stats['successful_companies']:,}ê°œ")
        print(f"ğŸ’° ë‰´ìŠ¤ ì €ì¥: {self.stats['financial_news_saved']:,}ê±´")
        print(f"â±ï¸ ì†Œìš” ì‹œê°„: {str(timedelta(seconds=int(elapsed_time)))}")
        
        if self.progress_file.exists():
            self.progress_file.unlink()
        
        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ìˆ˜ì •ëœ ì „ì²´ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--all', action='store_true', help='ëª¨ë“  íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘')
    parser.add_argument('--resume', action='store_true', help='ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì¬ê°œ')
    parser.add_argument('--delay', type=float, default=0.2, help='API í˜¸ì¶œ ê°„ê²© (ì´ˆ)')
    parser.add_argument('--batch_size', type=int, default=50, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--max_news', type=int, default=100, help='íšŒì‚¬ë‹¹ ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜')
    
    args = parser.parse_args()
    
    try:
        collector = FixedCompanyNewsCollector(
            delay=args.delay,
            batch_size=args.batch_size
        )
        collector.max_news_per_company = args.max_news
        
        if args.all or args.resume:
            print(f"ğŸš€ ìˆ˜ì •ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (ìŠ¤í‚¤ë§ˆ í˜¸í™˜ ë²„ì „)")
            print(f"âš™ï¸ ì„¤ì •: API ê°„ê²© {args.delay}ì´ˆ, ë°°ì¹˜ í¬ê¸° {args.batch_size}")
            print(f"{'='*60}")
            
            if collector.collect_all_company_news(resume=args.resume):
                print(f"\nâœ… ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
            else:
                print(f"\nâŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ë‹¨ë¨")
        else:
            parser.print_help()
            
    except ValueError as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    except KeyboardInterrupt:
        print("\nâ¹ï¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    except Exception as e:
        print(f"âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()
