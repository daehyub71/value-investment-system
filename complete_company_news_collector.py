#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì „ì²´ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
stock_data.dbì˜ company_info í…Œì´ë¸”ì— ìˆëŠ” ëª¨ë“  íšŒì‚¬ì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘

ì‹¤í–‰ ë°©ë²•:
python complete_company_news_collector.py --all
python complete_company_news_collector.py --from_date=2025-07-09 --to_date=2025-07-13
python complete_company_news_collector.py --resume  # ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì¬ê°œ
python complete_company_news_collector.py --batch_size=100 --delay=0.5
"""

import sys
import os
import argparse
import sqlite3
import requests
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
import logging
import time
from urllib.parse import quote
from dotenv import load_dotenv
import traceback

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class CompleteCompanyNewsCollector:
    """ì „ì²´ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    
    def __init__(self, delay=0.2, batch_size=50):
        # ë„¤ì´ë²„ API ì„¤ì •
        self.naver_client_id = os.getenv('NAVER_CLIENT_ID')
        self.naver_client_secret = os.getenv('NAVER_CLIENT_SECRET')
        
        if not self.naver_client_id or not self.naver_client_secret:
            raise ValueError("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        self.stock_db_path = Path('data/databases/stock_data.db')
        self.news_db_path = Path('data/databases/news_data.db')
        
        # ìˆ˜ì§‘ ì„¤ì •
        self.delay = delay  # API í˜¸ì¶œ ê°„ê²© (ì´ˆ)
        self.batch_size = batch_size  # ë°°ì¹˜ í¬ê¸°
        self.max_news_per_company = 100  # íšŒì‚¬ë‹¹ ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('news_collection.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ì§„í–‰ ìƒí™© ì¶”ì ìš© íŒŒì¼
        self.progress_file = Path('news_collection_progress.txt')
        
        # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
        self.financial_keywords = [
            'ì‹¤ì ', 'ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ë°°ë‹¹', 'íˆ¬ì', 'ì¸ìˆ˜í•©ë³‘', 'M&A',
            'ì‹ ì œí’ˆ', 'ì¶œì‹œ', 'ê³„ì•½', 'ìˆ˜ì£¼', 'íŠ¹í—ˆ', 'ê¸°ìˆ ê°œë°œ', 'ì—°êµ¬ê°œë°œ',
            'ì¦ì„¤', 'íˆ¬ì', 'ê³µì¥', 'ì‹œì„¤', 'ìƒì‚°', 'ê³µê¸‰', 'í™•ì¥',
            'ì£¼ê°€', 'ìƒìŠ¹', 'í•˜ë½', 'ëª©í‘œê°€', 'íˆ¬ìì˜ê²¬', 'ë§¤ìˆ˜', 'ë§¤ë„',
            'ë¶„í• ', 'í•©ë³‘', 'ìœ ìƒì¦ì', 'ë¬´ìƒì¦ì', 'ìì‚¬ì£¼', 'ë°°ë‹¹ê¸ˆ',
            'CEO', 'ëŒ€í‘œì´ì‚¬', 'ì„ì›', 'ì¸ì‚¬', 'ì¡°ì§ê°œí¸', 'ê²½ì˜ì§„',
            'ì—…ì ', 'ì„±ê³¼', 'ì „ë§', 'ê³„íš', 'ì „ëµ', 'ì‚¬ì—…', 'ë¶€ë¬¸'
        ]
        
        # ê°ì •ë¶„ì„ í‚¤ì›Œë“œ
        self.positive_words = [
            'ì„±ì¥', 'ì¦ê°€', 'ìƒìŠ¹', 'ê°œì„ ', 'í™•ëŒ€', 'í˜¸ì¡°', 'ì¢‹ì€', 'ê¸ì •', 'ì„±ê³µ',
            'ë‹¬ì„±', 'ëŒíŒŒ', 'ìµœê³ ', 'ìš°ìˆ˜', 'ê°•ì„¸', 'ê¸°ëŒ€', 'ì „ë§', 'í˜ì‹ ',
            'íšê¸°ì ', 'ë›°ì–´ë‚œ', 'ì•ˆì •ì ', 'ê²¬ê³ í•œ', 'íƒ„íƒ„í•œ', 'ë†’ì€', 'í°'
        ]
        
        self.negative_words = [
            'ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”', 'ì¶•ì†Œ', 'ìš°ë ¤', 'ë‚˜ìœ', 'ë¶€ì •', 'ì‹¤íŒ¨',
            'ë¶€ì¡±', 'ì†ì‹¤', 'ì ì', 'ìµœì €', 'ë¶€ì‹¤', 'ë¶ˆì•ˆ', 'ìœ„í—˜', 'í•˜í–¥',
            'ì–´ë ¤ìš´', 'í˜ë“ ', 'ì‹¬ê°í•œ', 'ë‚®ì€', 'ì‘ì€', 'ì•…ì˜í–¥', 'ì¶©ê²©'
        ]
        
        # í†µê³„ ì¶”ì 
        self.stats = {
            'total_companies': 0,
            'processed_companies': 0,
            'successful_companies': 0,
            'total_news_collected': 0,
            'financial_news_saved': 0,
            'api_calls': 0,
            'errors': 0,
            'start_time': None,
            'last_processed_company': None
        }
    
    def get_all_companies(self):
        """stock_data.dbì—ì„œ ëª¨ë“  íšŒì‚¬ ì •ë³´ ì¡°íšŒ"""
        try:
            if not self.stock_db_path.exists():
                raise FileNotFoundError("stock_data.db íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            with sqlite3.connect(self.stock_db_path) as conn:
                query = """
                    SELECT stock_code, company_name, market_cap, market_type
                    FROM company_info 
                    WHERE company_name IS NOT NULL 
                        AND company_name != ''
                        AND LENGTH(company_name) >= 2
                    ORDER BY 
                        CASE WHEN market_cap IS NOT NULL THEN market_cap ELSE 0 END DESC,
                        company_name
                """
                
                cursor = conn.execute(query)
                companies = cursor.fetchall()
                
                self.logger.info(f"ì „ì²´ íšŒì‚¬ ì¡°íšŒ ì™„ë£Œ: {len(companies)}ê°œ")
                return companies
                
        except Exception as e:
            self.logger.error(f"íšŒì‚¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def load_progress(self):
        """ì§„í–‰ ìƒí™© ë¡œë“œ"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        last_line = lines[-1].strip()
                        if ',' in last_line:
                            parts = last_line.split(',')
                            if len(parts) >= 2:
                                return int(parts[0]), parts[1]  # index, company_name
                return 0, None
            except Exception as e:
                self.logger.warning(f"ì§„í–‰ ìƒí™© ë¡œë“œ ì‹¤íŒ¨: {e}")
                return 0, None
        return 0, None
    
    def save_progress(self, index, company_name, stock_code):
        """ì§„í–‰ ìƒí™© ì €ì¥"""
        try:
            with open(self.progress_file, 'a', encoding='utf-8') as f:
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                f.write(f"{index},{company_name},{stock_code},{timestamp}\n")
        except Exception as e:
            self.logger.warning(f"ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def search_company_news(self, company_name, max_results=100):
        """íŠ¹ì • íšŒì‚¬ì˜ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            headers = {
                'X-Naver-Client-Id': self.naver_client_id,
                'X-Naver-Client-Secret': self.naver_client_secret
            }
            
            all_news = []
            
            # íšŒì‚¬ëª… ê²€ìƒ‰ (ë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ì •í™•í•œ ê²€ìƒ‰)
            search_queries = [
                f'"{company_name}"',  # ì •í™•í•œ íšŒì‚¬ëª…
                company_name,         # ì¼ë°˜ ê²€ìƒ‰
            ]
            
            for query in search_queries:
                for page in range(1, 4):  # ìµœëŒ€ 3í˜ì´ì§€
                    params = {
                        'query': query,
                        'display': 100,
                        'start': ((page - 1) * 100) + 1,
                        'sort': 'date'
                    }
                    
                    response = requests.get(self.base_url, headers=headers, params=params, timeout=30)
                    response.raise_for_status()
                    
                    self.stats['api_calls'] += 1
                    
                    data = response.json()
                    news_items = data.get('items', [])
                    
                    if not news_items:
                        break
                    
                    all_news.extend(news_items)
                    
                    # ì¶©ë¶„í•œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©´ ì¤‘ë‹¨
                    if len(all_news) >= max_results:
                        break
                    
                    # API í˜¸ì¶œ ì œí•œ ëŒ€ì‘
                    time.sleep(0.05)
                
                if len(all_news) >= max_results:
                    break
            
            # ì¤‘ë³µ ì œê±° (ë§í¬ ê¸°ì¤€)
            unique_news = []
            seen_links = set()
            
            for news in all_news:
                link = news.get('link', '')
                if link and link not in seen_links:
                    unique_news.append(news)
                    seen_links.add(link)
            
            self.stats['total_news_collected'] += len(unique_news)
            
            self.logger.debug(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {company_name} - {len(unique_news)}ê±´")
            return unique_news[:max_results]
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {company_name} - {e}")
            self.stats['errors'] += 1
            return []
    
    def filter_financial_news(self, news_items, company_name):
        """ê¸ˆìœµ/í€ë”ë©˜í„¸ ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§"""
        filtered_news = []
        
        for item in news_items:
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()
            content = f"{title} {description}"
            
            # HTML íƒœê·¸ ì œê±°
            content = re.sub(r'<[^>]+>', '', content)
            
            # íšŒì‚¬ëª… í¬í•¨ í™•ì¸ (í•„ìˆ˜)
            company_mentioned = False
            company_variations = [
                company_name.lower(),
                company_name.replace('(ì£¼)', '').replace('ãˆœ', '').lower(),
                company_name.replace('ì£¼ì‹íšŒì‚¬', '').lower()
            ]
            
            for variation in company_variations:
                if variation in content:
                    company_mentioned = True
                    break
            
            if not company_mentioned:
                continue
            
            # ê¸ˆìœµ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
            financial_score = 0
            matched_keywords = []
            
            for keyword in self.financial_keywords:
                if keyword.lower() in content:
                    financial_score += 1
                    matched_keywords.append(keyword)
            
            # ê¸ˆìœµ ê´€ë ¨ ë‰´ìŠ¤ë¡œ íŒì • (ìµœì†Œ 1ê°œ í‚¤ì›Œë“œ í¬í•¨)
            if financial_score >= 1:
                item['relevance_score'] = financial_score
                item['matched_keywords'] = matched_keywords
                filtered_news.append(item)
        
        return filtered_news
    
    def analyze_sentiment(self, text):
        """ê°ì •ë¶„ì„"""
        clean_text = re.sub(r'<[^>]+>', '', text).lower()
        
        positive_count = sum(1 for word in self.positive_words if word in clean_text)
        negative_count = sum(1 for word in self.negative_words if word in clean_text)
        
        total_words = positive_count + negative_count
        if total_words == 0:
            sentiment_score = 0.0
            confidence = 0.1
        else:
            sentiment_score = (positive_count - negative_count) / total_words
            confidence = min(total_words / 10, 1.0)
        
        # ê°ì • ë¼ë²¨
        if sentiment_score > 0.1:
            sentiment_label = 'positive'
        elif sentiment_score < -0.1:
            sentiment_label = 'negative'
        else:
            sentiment_label = 'neutral'
        
        return {
            'sentiment_score': sentiment_score,
            'sentiment_label': sentiment_label,
            'confidence': confidence,
            'positive_count': positive_count,
            'negative_count': negative_count
        }
    
    def save_news_to_db(self, news_items, stock_code, company_name):
        """ë‰´ìŠ¤ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            saved_count = 0
            
            with sqlite3.connect(self.news_db_path) as conn:
                for item in news_items:
                    try:
                        # HTML íƒœê·¸ ì œê±°
                        title = re.sub(r'<[^>]+>', '', item.get('title', ''))
                        description = re.sub(r'<[^>]+>', '', item.get('description', ''))
                        
                        # ê°ì •ë¶„ì„
                        sentiment = self.analyze_sentiment(f"{title} {description}")
                        
                        # ì¤‘ë³µ í™•ì¸ (ë§í¬ ê¸°ì¤€)
                        existing = conn.execute(
                            "SELECT id FROM news_articles WHERE link = ?",
                            (item.get('link', ''),)
                        ).fetchone()
                        
                        if existing:
                            continue  # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë‰´ìŠ¤
                        
                        # í‚¤ì›Œë“œ ë¬¸ìì—´ ìƒì„±
                        keywords_str = f"ê¸ì •:{sentiment['positive_count']},ë¶€ì •:{sentiment['negative_count']}"
                        if 'matched_keywords' in item:
                            keywords_str += f",ê¸ˆìœµ:{','.join(item['matched_keywords'][:5])}"
                        
                        # ìƒˆ ë‰´ìŠ¤ ì €ì¥
                        conn.execute('''
                            INSERT INTO news_articles 
                            (stock_code, company_name, title, description, originallink, link, pubDate, 
                             source, category, sentiment_score, sentiment_label, confidence_score, keywords, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            stock_code,
                            company_name,
                            title[:500],  # ì œëª© ê¸¸ì´ ì œí•œ
                            description[:1000],  # ì„¤ëª… ê¸¸ì´ ì œí•œ
                            item.get('originallink', ''),
                            item.get('link', ''),
                            item.get('pubDate', ''),
                            'ë„¤ì´ë²„ë‰´ìŠ¤',
                            'ê¸ˆìœµ',
                            sentiment['sentiment_score'],
                            sentiment['sentiment_label'],
                            sentiment['confidence'],
                            keywords_str,
                            datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        ))
                        
                        saved_count += 1
                        
                    except sqlite3.Error as e:
                        self.logger.warning(f"ê°œë³„ ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
                        continue
                
                conn.commit()
            
            self.stats['financial_news_saved'] += saved_count
            return saved_count
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            self.stats['errors'] += 1
            return 0
    
    def print_progress(self, current, total, company_name, news_count=0):
        """ì§„í–‰ ìƒí™© ì¶œë ¥"""
        percentage = (current / total) * 100
        elapsed_time = time.time() - self.stats['start_time']
        
        if current > 0:
            avg_time_per_company = elapsed_time / current
            remaining_companies = total - current
            eta_seconds = avg_time_per_company * remaining_companies
            eta_str = str(timedelta(seconds=int(eta_seconds)))
        else:
            eta_str = "ê³„ì‚° ì¤‘..."
        
        print(f"\rì§„í–‰ë¥ : {current:,}/{total:,} ({percentage:.1f}%) | "
              f"í˜„ì¬: {company_name[:20]} | ë‰´ìŠ¤: {news_count}ê±´ | "
              f"ê²½ê³¼: {str(timedelta(seconds=int(elapsed_time)))} | "
              f"ì˜ˆìƒ ì™„ë£Œ: {eta_str}", end='', flush=True)
    
    def print_statistics(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        elapsed_time = time.time() - self.stats['start_time']
        
        print(f"\n\n{'='*80}")
        print(f"ğŸ“Š ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ í†µê³„")
        print(f"{'='*80}")
        print(f"ğŸ¢ ì „ì²´ íšŒì‚¬ ìˆ˜: {self.stats['total_companies']:,}ê°œ")
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {self.stats['processed_companies']:,}ê°œ")
        print(f"ğŸ¯ ìˆ˜ì§‘ ì„±ê³µ: {self.stats['successful_companies']:,}ê°œ")
        print(f"ğŸ“° ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘: {self.stats['total_news_collected']:,}ê±´")
        print(f"ğŸ’° ê¸ˆìœµ ë‰´ìŠ¤ ì €ì¥: {self.stats['financial_news_saved']:,}ê±´")
        print(f"ğŸ”— API í˜¸ì¶œ ìˆ˜: {self.stats['api_calls']:,}íšŒ")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {self.stats['errors']:,}ê±´")
        print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {str(timedelta(seconds=int(elapsed_time)))}")
        
        if self.stats['processed_companies'] > 0:
            success_rate = (self.stats['successful_companies'] / self.stats['processed_companies']) * 100
            avg_news_per_company = self.stats['financial_news_saved'] / self.stats['successful_companies'] if self.stats['successful_companies'] > 0 else 0
            
            print(f"ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
            print(f"ğŸ“Š íšŒì‚¬ë‹¹ í‰ê·  ë‰´ìŠ¤: {avg_news_per_company:.1f}ê±´")
    
    def collect_all_company_news(self, resume=False, from_date=None, to_date=None):
        """ëª¨ë“  íšŒì‚¬ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        self.stats['start_time'] = time.time()
        
        # íšŒì‚¬ ëª©ë¡ ì¡°íšŒ
        companies = self.get_all_companies()
        if not companies:
            self.logger.error("ìˆ˜ì§‘í•  íšŒì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        self.stats['total_companies'] = len(companies)
        self.logger.info(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: {len(companies):,}ê°œ íšŒì‚¬")
        
        # ì§„í–‰ ìƒí™© ë¡œë“œ (ì¬ê°œ ëª¨ë“œ)
        start_index = 0
        if resume:
            start_index, last_company = self.load_progress()
            if start_index > 0:
                self.logger.info(f"ìˆ˜ì§‘ ì¬ê°œ: {start_index}ë²ˆì§¸ë¶€í„° (ë§ˆì§€ë§‰: {last_company})")
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for i in range(start_index, len(companies)):
            stock_code, company_name, market_cap, market_type = companies[i]
            
            try:
                self.stats['processed_companies'] += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                self.print_progress(i + 1, len(companies), company_name)
                
                # ë‰´ìŠ¤ ê²€ìƒ‰
                news_items = self.search_company_news(company_name, self.max_news_per_company)
                
                if not news_items:
                    # ë‰´ìŠ¤ê°€ ì—†ëŠ” ê²½ìš°ë„ ì§„í–‰ ìƒí™© ì €ì¥
                    self.save_progress(i, company_name, stock_code)
                    continue
                
                # ê¸ˆìœµ ë‰´ìŠ¤ í•„í„°ë§
                filtered_news = self.filter_financial_news(news_items, company_name)
                
                if not filtered_news:
                    self.save_progress(i, company_name, stock_code)
                    continue
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                saved_count = self.save_news_to_db(filtered_news, stock_code, company_name)
                
                if saved_count > 0:
                    self.stats['successful_companies'] += 1
                    self.logger.debug(f"ìˆ˜ì§‘ ì™„ë£Œ: {company_name} - {saved_count}ê±´ ì €ì¥")
                
                # ì§„í–‰ ìƒí™© ì €ì¥
                self.save_progress(i, company_name, stock_code)
                
                # API í˜¸ì¶œ ì œí•œ ëŒ€ì‘
                time.sleep(self.delay)
                
                # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¡œê·¸ ì¶œë ¥
                if (i + 1) % self.batch_size == 0:
                    self.logger.info(f"\në°°ì¹˜ ì™„ë£Œ: {i + 1:,}/{len(companies):,} "
                                   f"(ì„±ê³µ: {self.stats['successful_companies']:,}, "
                                   f"ì €ì¥: {self.stats['financial_news_saved']:,}ê±´)")
                
            except KeyboardInterrupt:
                print(f"\n\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
                print(f"ğŸ“ ì¤‘ë‹¨ ì§€ì : {i + 1}/{len(companies)} - {company_name}")
                print(f"ğŸ’¡ ì¬ê°œí•˜ë ¤ë©´: python {sys.argv[0]} --resume")
                self.print_statistics()
                return False
                
            except Exception as e:
                self.logger.error(f"íšŒì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {company_name} - {e}")
                self.stats['errors'] += 1
                self.save_progress(i, company_name, stock_code)
                continue
        
        # ìµœì¢… í†µê³„ ì¶œë ¥
        self.print_statistics()
        
        # ì§„í–‰ ìƒí™© íŒŒì¼ ì‚­ì œ (ì™„ë£Œ)
        if self.progress_file.exists():
            self.progress_file.unlink()
        
        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì „ì²´ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--all', action='store_true', help='ëª¨ë“  íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘')
    parser.add_argument('--resume', action='store_true', help='ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì¬ê°œ')
    parser.add_argument('--from_date', type=str, help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)')
    parser.add_argument('--to_date', type=str, help='ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)')
    parser.add_argument('--delay', type=float, default=0.2, help='API í˜¸ì¶œ ê°„ê²© (ì´ˆ)')
    parser.add_argument('--batch_size', type=int, default=50, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--max_news', type=int, default=100, help='íšŒì‚¬ë‹¹ ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜')
    
    args = parser.parse_args()
    
    try:
        collector = CompleteCompanyNewsCollector(
            delay=args.delay,
            batch_size=args.batch_size
        )
        collector.max_news_per_company = args.max_news
        
        if args.all or args.resume:
            print(f"ğŸš€ ì „ì²´ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
            print(f"âš™ï¸ ì„¤ì •: API ê°„ê²© {args.delay}ì´ˆ, ë°°ì¹˜ í¬ê¸° {args.batch_size}")
            print(f"ğŸ“Š íšŒì‚¬ë‹¹ ìµœëŒ€ ë‰´ìŠ¤: {args.max_news}ê±´")
            print(f"{'='*60}")
            
            if collector.collect_all_company_news(
                resume=args.resume,
                from_date=args.from_date,
                to_date=args.to_date
            ):
                print(f"\nâœ… ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
            else:
                print(f"\nâŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ë‹¨ë¨")
        else:
            parser.print_help()
            
    except ValueError as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ .env íŒŒì¼ì—ì„œ ë„¤ì´ë²„ API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except KeyboardInterrupt:
        print("\nâ¹ï¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    except Exception as e:
        print(f"âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()
