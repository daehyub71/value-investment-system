#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼ ì´í›„ì˜ ë‰´ìŠ¤ë§Œ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜ì§‘

ì‹¤í–‰ ë°©ë²•:
python incremental_news_collector.py --from_date=2025-07-09 --to_date=2025-07-13
python incremental_news_collector.py --auto  # ìë™ìœ¼ë¡œ ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼ ì´í›„ ìˆ˜ì§‘
python incremental_news_collector.py --stock_code=000660 --from_date=2025-07-09
"""

import sys
import os
import argparse
import sqlite3
import requests
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
import logging
import time
from urllib.parse import quote
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class IncrementalNewsCollector:
    """ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ë„¤ì´ë²„ API ì„¤ì •
        self.naver_client_id = os.getenv('NAVER_CLIENT_ID')
        self.naver_client_secret = os.getenv('NAVER_CLIENT_SECRET')
        
        if not self.naver_client_id or not self.naver_client_secret:
            raise ValueError("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        self.db_path = Path('data/databases/news_data.db')
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
        # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
        self.financial_keywords = [
            'ì‹¤ì ', 'ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ë°°ë‹¹', 'íˆ¬ì', 'ì¸ìˆ˜í•©ë³‘', 'M&A',
            'ì‹ ì œí’ˆ', 'ì¶œì‹œ', 'ê³„ì•½', 'ìˆ˜ì£¼', 'íŠ¹í—ˆ', 'ê¸°ìˆ ê°œë°œ', 'ì—°êµ¬ê°œë°œ',
            'ì¦ì„¤', 'íˆ¬ì', 'ê³µì¥', 'ì‹œì„¤', 'ìƒì‚°', 'ê³µê¸‰',
            'ì£¼ê°€', 'ìƒìŠ¹', 'í•˜ë½', 'ëª©í‘œê°€', 'íˆ¬ìì˜ê²¬', 'ë§¤ìˆ˜', 'ë§¤ë„',
            'ë¶„í• ', 'í•©ë³‘', 'ìœ ìƒì¦ì', 'ë¬´ìƒì¦ì', 'ìì‚¬ì£¼',
            'CEO', 'ëŒ€í‘œì´ì‚¬', 'ì„ì›', 'ì¸ì‚¬', 'ì¡°ì§ê°œí¸'
        ]
        
        # ê°ì •ë¶„ì„ í‚¤ì›Œë“œ
        self.positive_words = [
            'ì„±ì¥', 'ì¦ê°€', 'ìƒìŠ¹', 'ê°œì„ ', 'í™•ëŒ€', 'í˜¸ì¡°', 'ì¢‹ì€', 'ê¸ì •', 'ì„±ê³µ',
            'ë‹¬ì„±', 'ëŒíŒŒ', 'ìµœê³ ', 'ìš°ìˆ˜', 'ê°•ì„¸', 'ê¸°ëŒ€', 'ì „ë§', 'í˜ì‹ '
        ]
        
        self.negative_words = [
            'ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”', 'ì¶•ì†Œ', 'ìš°ë ¤', 'ë‚˜ìœ', 'ë¶€ì •', 'ì‹¤íŒ¨',
            'ë¶€ì¡±', 'ì†ì‹¤', 'ì ì', 'ìµœì €', 'ë¶€ì‹¤', 'ë¶ˆì•ˆ', 'ìœ„í—˜', 'í•˜í–¥'
        ]
    
    def get_last_collection_date(self, stock_code=None):
        """ë§ˆì§€ë§‰ ë‰´ìŠ¤ ìˆ˜ì§‘ ë‚ ì§œ ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                if stock_code:
                    # íŠ¹ì • ì¢…ëª©ì˜ ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼
                    query = """
                        SELECT MAX(date(created_at)) 
                        FROM news_articles 
                        WHERE stock_code = ?
                    """
                    result = conn.execute(query, (stock_code,)).fetchone()
                else:
                    # ì „ì²´ ë‰´ìŠ¤ì˜ ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼
                    query = """
                        SELECT MAX(date(created_at)) 
                        FROM news_articles
                    """
                    result = conn.execute(query).fetchone()
                
                if result and result[0]:
                    return result[0]
                else:
                    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 7ì¼ ì „ë¶€í„°
                    return (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
                    
        except Exception as e:
            self.logger.error(f"ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    
    def get_company_list(self, limit=50):
        """íšŒì‚¬ ëª©ë¡ ì¡°íšŒ"""
        try:
            stock_db_path = Path('data/databases/stock_data.db')
            if not stock_db_path.exists():
                self.logger.error("ì£¼ì‹ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
                
            with sqlite3.connect(stock_db_path) as conn:
                cursor = conn.execute(f"""
                    SELECT stock_code, company_name, market_cap
                    FROM company_info 
                    WHERE market_cap IS NOT NULL AND market_cap > 0
                    ORDER BY market_cap DESC 
                    LIMIT {limit}
                """)
                return cursor.fetchall()
                
        except Exception as e:
            self.logger.error(f"íšŒì‚¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def search_news_by_date(self, keyword, start_date, end_date, max_results=100):
        """ë‚ ì§œ ë²”ìœ„ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            headers = {
                'X-Naver-Client-Id': self.naver_client_id,
                'X-Naver-Client-Secret': self.naver_client_secret
            }
            
            all_news = []
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ APIëŠ” ë‚ ì§œ í•„í„°ê°€ ì œí•œì ì´ë¯€ë¡œ ì „ì²´ ê²€ìƒ‰ í›„ í•„í„°ë§
            for page in range(1, 6):  # ìµœëŒ€ 5í˜ì´ì§€ (500ê°œ ë‰´ìŠ¤)
                params = {
                    'query': keyword,
                    'display': 100,
                    'start': ((page - 1) * 100) + 1,
                    'sort': 'date'
                }
                
                response = requests.get(self.base_url, headers=headers, params=params, timeout=30)
                response.raise_for_status()
                
                data = response.json()
                news_items = data.get('items', [])
                
                if not news_items:
                    break
                
                # ë‚ ì§œ í•„í„°ë§
                filtered_items = self.filter_by_date_range(news_items, start_date, end_date)
                all_news.extend(filtered_items)
                
                # ì¶©ë¶„í•œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©´ ì¤‘ë‹¨
                if len(all_news) >= max_results:
                    break
                
                # API í˜¸ì¶œ ì œí•œ ëŒ€ì‘
                time.sleep(0.1)
            
            # ì¤‘ë³µ ì œê±°
            unique_news = []
            seen_links = set()
            
            for news in all_news:
                link = news.get('link', '')
                if link not in seen_links:
                    unique_news.append(news)
                    seen_links.add(link)
            
            self.logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ (í‚¤ì›Œë“œ: {keyword}): {len(unique_news)}ê±´")
            return unique_news[:max_results]
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨ (í‚¤ì›Œë“œ: {keyword}): {e}")
            return []
    
    def filter_by_date_range(self, news_items, start_date, end_date):
        """ë‚ ì§œ ë²”ìœ„ë¡œ ë‰´ìŠ¤ í•„í„°ë§"""
        filtered_news = []
        
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d') + timedelta(days=1)  # í¬í•¨
        
        for item in news_items:
            pub_date_str = item.get('pubDate', '')
            if not pub_date_str:
                continue
            
            try:
                # RFC 2822 í˜•ì‹ íŒŒì‹±: Wed, 25 Jun 2025 18:16:00 +0900
                if '+' in pub_date_str:
                    pub_date_str = pub_date_str.split(' +')[0]
                
                pub_date = datetime.strptime(pub_date_str, '%a, %d %b %Y %H:%M:%S')
                
                if start_dt <= pub_date < end_dt:
                    filtered_news.append(item)
                    
            except Exception as e:
                # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ì‹œ ìµœì‹  ë‰´ìŠ¤ë¡œ ê°„ì£¼
                filtered_news.append(item)
                continue
        
        return filtered_news
    
    def filter_financial_news(self, news_items, company_name=None):
        """ê¸ˆìœµ ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§"""
        filtered_news = []
        
        for item in news_items:
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()
            content = f"{title} {description}"
            
            # HTML íƒœê·¸ ì œê±°
            content = re.sub(r'<[^>]+>', '', content)
            
            # ê¸ˆìœµ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
            financial_score = 0
            for keyword in self.financial_keywords:
                if keyword.lower() in content:
                    financial_score += 1
            
            # íšŒì‚¬ëª… í¬í•¨ ì—¬ë¶€ í™•ì¸
            company_score = 0
            if company_name:
                if company_name.lower() in content:
                    company_score += 2
            
            # ì´ ì ìˆ˜ê°€ ì¼ì • ì´ìƒì´ë©´ í¬í•¨
            total_score = financial_score + company_score
            if total_score >= 1:
                item['relevance_score'] = total_score
                filtered_news.append(item)
        
        return filtered_news
    
    def analyze_sentiment(self, text):
        """ê°ì •ë¶„ì„"""
        clean_text = re.sub(r'<[^>]+>', '', text).lower()
        
        positive_count = sum(1 for word in self.positive_words if word in clean_text)
        negative_count = sum(1 for word in self.negative_words if word in clean_text)
        
        total_words = positive_count + negative_count
        if total_words == 0:
            sentiment_score = 0.0
            confidence = 0.1
        else:
            sentiment_score = (positive_count - negative_count) / total_words
            confidence = min(total_words / 10, 1.0)
        
        # ê°ì • ë¼ë²¨
        if sentiment_score > 0.1:
            sentiment_label = 'positive'
        elif sentiment_score < -0.1:
            sentiment_label = 'negative'
        else:
            sentiment_label = 'neutral'
        
        return {
            'sentiment_score': sentiment_score,
            'sentiment_label': sentiment_label,
            'confidence': confidence,
            'keywords': f"ê¸ì •:{positive_count},ë¶€ì •:{negative_count}"
        }
    
    def save_news_to_db(self, news_items, stock_code, company_name):
        """ë‰´ìŠ¤ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            saved_count = 0
            
            with sqlite3.connect(self.db_path) as conn:
                for item in news_items:
                    # HTML íƒœê·¸ ì œê±°
                    title = re.sub(r'<[^>]+>', '', item.get('title', ''))
                    description = re.sub(r'<[^>]+>', '', item.get('description', ''))
                    
                    # ê°ì •ë¶„ì„
                    sentiment = self.analyze_sentiment(f"{title} {description}")
                    
                    try:
                        # ì¤‘ë³µ í™•ì¸ (ë§í¬ ê¸°ì¤€)
                        existing = conn.execute(
                            "SELECT id FROM news_articles WHERE link = ?",
                            (item.get('link', ''),)
                        ).fetchone()
                        
                        if existing:
                            continue  # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë‰´ìŠ¤
                        
                        # ìƒˆ ë‰´ìŠ¤ ì €ì¥
                        conn.execute('''
                            INSERT INTO news_articles 
                            (stock_code, title, description, originallink, link, pubDate, 
                             source, category, sentiment_score, sentiment_label, confidence_score, keywords, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            stock_code,
                            title,
                            description,
                            item.get('originallink', ''),
                            item.get('link', ''),
                            item.get('pubDate', ''),
                            'ë„¤ì´ë²„ë‰´ìŠ¤',
                            'ê¸ˆìœµ',
                            sentiment['sentiment_score'],
                            sentiment['sentiment_label'],
                            sentiment['confidence'],
                            sentiment['keywords'],
                            datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        ))
                        
                        saved_count += 1
                        
                    except sqlite3.Error as e:
                        self.logger.warning(f"ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
                        continue
                
                conn.commit()
            
            return saved_count
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def collect_incremental_news(self, from_date, to_date, stock_code=None, limit=50):
        """ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        self.logger.info(f"ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: {from_date} ~ {to_date}")
        
        if stock_code:
            # íŠ¹ì • ì¢…ëª©ë§Œ ìˆ˜ì§‘
            company_list = [(stock_code, self.get_company_name(stock_code), 0)]
        else:
            # ì£¼ìš” ì¢…ëª©ë“¤ ìˆ˜ì§‘
            company_list = self.get_company_list(limit)
        
        if not company_list:
            self.logger.error("ìˆ˜ì§‘í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        total_saved = 0
        success_count = 0
        
        for idx, (stock_code, company_name, market_cap) in enumerate(company_list):
            self.logger.info(f"ì§„í–‰ë¥ : {idx+1}/{len(company_list)} - {company_name}({stock_code})")
            
            try:
                # í•´ë‹¹ ê¸°ê°„ì˜ ë‰´ìŠ¤ ê²€ìƒ‰
                news_items = self.search_news_by_date(company_name, from_date, to_date)
                
                if not news_items:
                    self.logger.info(f"ìƒˆ ë‰´ìŠ¤ ì—†ìŒ: {company_name}")
                    continue
                
                # ê¸ˆìœµ ë‰´ìŠ¤ í•„í„°ë§
                filtered_news = self.filter_financial_news(news_items, company_name)
                
                if not filtered_news:
                    self.logger.info(f"ê¸ˆìœµ ë‰´ìŠ¤ ì—†ìŒ: {company_name}")
                    continue
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                saved_count = self.save_news_to_db(filtered_news, stock_code, company_name)
                
                if saved_count > 0:
                    total_saved += saved_count
                    success_count += 1
                    self.logger.info(f"ì €ì¥ ì™„ë£Œ: {company_name} - {saved_count}ê±´")
                
                # API í˜¸ì¶œ ì œí•œ ëŒ€ì‘
                time.sleep(0.2)
                
            except Exception as e:
                self.logger.error(f"ìˆ˜ì§‘ ì‹¤íŒ¨: {company_name} - {e}")
                continue
        
        self.logger.info(f"ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{len(company_list)} ì¢…ëª©, ì´ {total_saved}ê±´ ì €ì¥")
        return total_saved > 0
    
    def get_company_name(self, stock_code):
        """ì¢…ëª©ì½”ë“œë¡œ íšŒì‚¬ëª… ì¡°íšŒ"""
        try:
            stock_db_path = Path('data/databases/stock_data.db')
            if stock_db_path.exists():
                with sqlite3.connect(stock_db_path) as conn:
                    result = conn.execute(
                        "SELECT company_name FROM company_info WHERE stock_code = ?",
                        (stock_code,)
                    ).fetchone()
                    
                    if result:
                        return result[0]
            
            return f"ì¢…ëª©{stock_code}"
            
        except Exception as e:
            self.logger.error(f"íšŒì‚¬ëª… ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return f"ì¢…ëª©{stock_code}"

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--from_date', type=str, help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)')
    parser.add_argument('--to_date', type=str, help='ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)')
    parser.add_argument('--stock_code', type=str, help='íŠ¹ì • ì¢…ëª©ì½”ë“œ')
    parser.add_argument('--auto', action='store_true', help='ìë™ìœ¼ë¡œ ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼ ì´í›„ ìˆ˜ì§‘')
    parser.add_argument('--limit', type=int, default=50, help='ìˆ˜ì§‘í•  ì¢…ëª© ìˆ˜')
    
    args = parser.parse_args()
    
    try:
        collector = IncrementalNewsCollector()
        
        if args.auto:
            # ìë™ ëª¨ë“œ: ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼ ì´í›„ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€
            last_date = collector.get_last_collection_date(args.stock_code)
            today = datetime.now().strftime('%Y-%m-%d')
            
            print(f"ğŸ” ìë™ ì¦ë¶„ ìˆ˜ì§‘")
            print(f"ğŸ“… ê¸°ê°„: {last_date} ~ {today}")
            
            if collector.collect_incremental_news(last_date, today, args.stock_code, args.limit):
                print("âœ… ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì„±ê³µ!")
            else:
                print("âŒ ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
                
        elif args.from_date and args.to_date:
            # ìˆ˜ë™ ëª¨ë“œ: ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„
            print(f"ğŸ” ìˆ˜ë™ ì¦ë¶„ ìˆ˜ì§‘")
            print(f"ğŸ“… ê¸°ê°„: {args.from_date} ~ {args.to_date}")
            
            if collector.collect_incremental_news(args.from_date, args.to_date, args.stock_code, args.limit):
                print("âœ… ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì„±ê³µ!")
            else:
                print("âŒ ì¦ë¶„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
        else:
            parser.print_help()
            
    except ValueError as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ .env íŒŒì¼ì—ì„œ ë„¤ì´ë²„ API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()
