#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì „ì²´ 3967ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ - company_info ê¸°ë°˜
"""

import sqlite3
import requests
import re
import time
import os
from datetime import datetime, timedelta
from dateutil import parser as date_parser
from dotenv import load_dotenv

load_dotenv()

class FullStocksNewsCollector:
    def __init__(self):
        self.client_id = os.getenv('NAVER_CLIENT_ID')
        self.client_secret = os.getenv('NAVER_CLIENT_SECRET')
        self.stock_db = 'data/databases/stock_data.db'
        self.news_db = 'data/databases/news_data.db'
        
        if not self.client_id or not self.client_secret:
            raise ValueError("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ”§ API í‚¤ í™•ì¸ ì™„ë£Œ")
    
    def get_all_stocks_from_company_info(self):
        """company_info í…Œì´ë¸”ì—ì„œ ì „ì²´ ì¢…ëª© ë° íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°"""
        try:
            with sqlite3.connect(self.stock_db) as conn:
                cursor = conn.cursor()
                
                print("ğŸ“Š company_info í…Œì´ë¸”ì—ì„œ ì¢…ëª© ì •ë³´ ë¡œë”©...")
                
                # ì¢…ëª©ì½”ë“œì™€ íšŒì‚¬ëª… í•¨ê»˜ ì¡°íšŒ
                cursor.execute("""
                    SELECT stock_code, company_name 
                    FROM company_info 
                    WHERE stock_code IS NOT NULL 
                      AND LENGTH(stock_code) = 6
                      AND company_name IS NOT NULL
                      AND company_name != ''
                    ORDER BY stock_code
                """)
                
                stocks_data = cursor.fetchall()
                
                # ìœ íš¨í•œ ì¢…ëª©ë§Œ í•„í„°ë§ (ìˆ«ìë¡œë§Œ êµ¬ì„±)
                valid_stocks = []
                for stock_code, company_name in stocks_data:
                    if isinstance(stock_code, str) and stock_code.isdigit() and len(stock_code) == 6:
                        valid_stocks.append((stock_code, company_name))
                
                print(f"âœ… {len(valid_stocks)}ê°œ ìœ íš¨ ì¢…ëª© ë¡œë”© ì™„ë£Œ")
                
                # ìƒ˜í”Œ ì¶œë ¥
                print(f"ğŸ“‹ ìƒ˜í”Œ ì¢…ëª©:")
                for i, (code, name) in enumerate(valid_stocks[:10]):
                    print(f"   {i+1:2d}. {name}({code})")
                
                if len(valid_stocks) > 10:
                    print(f"   ... ì™¸ {len(valid_stocks)-10}ê°œ")
                
                return valid_stocks
                
        except Exception as e:
            print(f"âŒ ì¢…ëª© ì •ë³´ ë¡œë”© ì‹¤íŒ¨: {e}")
            return []
    
    def search_latest_news(self, company_name, stock_code, days_back=30):
        """ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ (ìµœì í™”ëœ ë²„ì „)"""
        try:
            headers = {
                'X-Naver-Client-Id': self.client_id,
                'X-Naver-Client-Secret': self.client_secret
            }
            
            all_news = []
            cutoff_date = datetime.now().date() - timedelta(days=days_back)
            
            # íšŒì‚¬ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ì¤„ì—¬ì„œ ê²€ìƒ‰
            search_name = company_name[:10] if len(company_name) > 10 else company_name
            
            # ìµœëŒ€ 2í˜ì´ì§€ë§Œ ê²€ìƒ‰ (API íš¨ìœ¨ì„±)
            for page in range(1, 3):
                start_index = (page - 1) * 100 + 1
                
                params = {
                    'query': search_name,
                    'display': 100,
                    'start': start_index,
                    'sort': 'date'
                }
                
                response = requests.get(
                    "https://openapi.naver.com/v1/search/news.json",
                    headers=headers,
                    params=params,
                    timeout=10  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                )
                response.raise_for_status()
                
                data = response.json()
                news_items = data.get('items', [])
                
                if not news_items:
                    break
                
                # ë‚ ì§œ í•„í„°ë§
                recent_news = []
                old_count = 0
                
                for item in news_items:
                    pub_date_str = item.get('pubDate', '')
                    try:
                        if pub_date_str:
                            pub_date = date_parser.parse(pub_date_str).date()
                            if pub_date >= cutoff_date:
                                recent_news.append(item)
                            else:
                                old_count += 1
                        else:
                            recent_news.append(item)
                    except:
                        recent_news.append(item)
                
                all_news.extend(recent_news)
                
                # ì˜¤ë˜ëœ ë‰´ìŠ¤ê°€ ë§ìœ¼ë©´ ì¤‘ë‹¨
                if old_count > len(recent_news) and len(recent_news) > 0:
                    break
                
                time.sleep(0.05)  # ì§§ì€ ëŒ€ê¸°
            
            # ì¤‘ë³µ ì œê±°
            seen_urls = set()
            unique_news = []
            
            for item in all_news:
                url = item.get('originallink', item.get('link', ''))
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    unique_news.append(item)
            
            return unique_news
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒì‹œ ì¡°ìš©íˆ ë„˜ì–´ê° (ë¡œê·¸ ìµœì†Œí™”)
            return []
    
    def save_news_to_database(self, stock_code, company_name, news_items):
        """ë‰´ìŠ¤ ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬)"""
        if not news_items:
            return 0
        
        saved_count = 0
        
        try:
            with sqlite3.connect(self.news_db) as conn:
                # ê¸°ì¡´ URL ëª©ë¡ ì¡°íšŒ (ì¤‘ë³µ ë°©ì§€)
                existing_urls = set()
                cursor = conn.execute("SELECT originallink FROM news_articles WHERE stock_code = ?", (stock_code,))
                existing_urls.update(row[0] for row in cursor.fetchall() if row[0])
                
                for item in news_items:
                    try:
                        originallink = item.get('originallink', '')
                        
                        # ì¤‘ë³µ ì²´í¬
                        if originallink in existing_urls:
                            continue
                        
                        title = re.sub(r'<[^>]+>', '', item.get('title', ''))
                        description = re.sub(r'<[^>]+>', '', item.get('description', ''))
                        
                        # ë¹ ë¥¸ ê°ì •ë¶„ì„
                        content = f"{title} {description}".lower()
                        pos_count = sum(1 for word in ['ì„±ì¥', 'ì¦ê°€', 'ìƒìŠ¹', 'ê°œì„ ', 'í˜¸ì¡°', 'ê¸ì •'] if word in content)
                        neg_count = sum(1 for word in ['ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”', 'ìš°ë ¤', 'ë¶€ì •'] if word in content)
                        
                        sentiment_score = (pos_count - neg_count) * 0.1
                        sentiment_label = 'positive' if sentiment_score > 0 else ('negative' if sentiment_score < 0 else 'neutral')
                        
                        # ì €ì¥
                        conn.execute('''
                            INSERT OR IGNORE INTO news_articles 
                            (stock_code, title, description, originallink, link, pubDate, 
                             source, category, sentiment_score, sentiment_label, confidence_score, 
                             keywords, created_at, company_name)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            stock_code, title, description, originallink, item.get('link', ''),
                            item.get('pubDate', ''), 'ë„¤ì´ë²„ë‰´ìŠ¤', 'ê¸ˆìœµ',
                            sentiment_score, sentiment_label, 0.5,
                            f"pos:{pos_count},neg:{neg_count}",
                            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            company_name
                        ))
                        
                        saved_count += 1
                        existing_urls.add(originallink)  # ì¤‘ë³µ ë°©ì§€ìš© ì—…ë°ì´íŠ¸
                        
                    except Exception:
                        continue
                
                conn.commit()
                
        except Exception:
            pass
        
        return saved_count
    
    def collect_all_news_optimized(self, days_back=30, max_stocks=None, start_from=0, batch_size=100):
        """ìµœì í™”ëœ ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘"""
        print(f"ğŸš€ ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœì í™” ë²„ì „)")
        print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: ìµœê·¼ {days_back}ì¼")
        print(f"ğŸ•’ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)
        
        # 1. ì „ì²´ ì¢…ëª© ë¡œë”©
        all_stocks = self.get_all_stocks_from_company_info()
        
        if not all_stocks:
            print("âŒ ì¢…ëª© ë°ì´í„°ë¥¼ ë¡œë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ë²”ìœ„ ì„¤ì •
        if start_from > 0:
            all_stocks = all_stocks[start_from:]
            print(f"ğŸ“Š {start_from}ë²ˆì§¸ë¶€í„° ì‹œì‘")
        
        if max_stocks:
            all_stocks = all_stocks[:max_stocks]
        
        print(f"ğŸ“Š ì²˜ë¦¬ ëŒ€ìƒ: {len(all_stocks)}ê°œ ì¢…ëª©")
        
        # 3. ë°°ì¹˜ë³„ ì²˜ë¦¬
        total_success = 0
        total_news = 0
        total_failed = 0
        
        for idx, (stock_code, company_name) in enumerate(all_stocks):
            try:
                # ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ (ë§¤ ì¢…ëª©ë§ˆë‹¤ ì¶œë ¥í•˜ì§€ ì•ŠìŒ)
                if idx % 50 == 0 or idx < 10:
                    progress = f"[{idx+1:4d}/{len(all_stocks)}]"
                    print(f"\\n{progress} {company_name}({stock_code})")
                elif idx % 10 == 0:
                    print(".", end="", flush=True)
                
                # ë‰´ìŠ¤ ê²€ìƒ‰
                news_items = self.search_latest_news(company_name, stock_code, days_back)
                
                if news_items:
                    saved_count = self.save_news_to_database(stock_code, company_name, news_items)
                    if saved_count > 0:
                        total_success += 1
                        total_news += saved_count
                        if idx % 50 == 0 or idx < 10:
                            print(f"   âœ… {saved_count}ê°œ ë‰´ìŠ¤ ì €ì¥")
                    else:
                        if idx % 50 == 0 or idx < 10:
                            print(f"   âš ï¸ ëª¨ë‘ ì¤‘ë³µ")
                else:
                    total_failed += 1
                    if idx % 50 == 0 or idx < 10:
                        print(f"   âŒ ë‰´ìŠ¤ ì—†ìŒ")
                
                # API ì œí•œ ì¤€ìˆ˜ (ë„¤ì´ë²„ ì´ˆë‹¹ 10íšŒ)
                time.sleep(0.12)
                
                # ë°°ì¹˜ë³„ ì¤‘ê°„ ë³´ê³ 
                if (idx + 1) % batch_size == 0:
                    elapsed = (idx + 1) / len(all_stocks) * 100
                    success_rate = (total_success / (idx + 1)) * 100
                    
                    print(f"\\nğŸ“Š ë°°ì¹˜ ì™„ë£Œ [{idx+1}/{len(all_stocks)}] ({elapsed:.1f}%)")
                    print(f"   ì„±ê³µ: {total_success}ê°œ ì¢…ëª© ({success_rate:.1f}%)")
                    print(f"   ë‰´ìŠ¤: {total_news}ê°œ ìˆ˜ì§‘")
                    print(f"   ì‹¤íŒ¨: {total_failed}ê°œ")
                    print(f"   ì˜ˆìƒ ì™„ë£Œ: {datetime.now() + timedelta(seconds=(len(all_stocks)-(idx+1))*0.12)}")
                
            except KeyboardInterrupt:
                print(f"\\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨ (ì§„í–‰ë¥ : {idx+1}/{len(all_stocks)})")
                break
            except Exception as e:
                total_failed += 1
                if idx < 10:  # ì²˜ìŒ 10ê°œë§Œ ì˜¤ë¥˜ ì¶œë ¥
                    print(f"   âŒ ì˜¤ë¥˜: {e}")
                continue
        
        # ìµœì¢… ê²°ê³¼
        print(f"\\n" + "=" * 70)
        print(f"ğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ•’ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"   â€¢ ì²˜ë¦¬ ì¢…ëª©: {len(all_stocks)}ê°œ")
        print(f"   â€¢ ì„±ê³µ ì¢…ëª©: {total_success}ê°œ ({(total_success/len(all_stocks)*100):.1f}%)")
        print(f"   â€¢ ì‹¤íŒ¨ ì¢…ëª©: {total_failed}ê°œ")
        print(f"   â€¢ ìˆ˜ì§‘ ë‰´ìŠ¤: ì´ {total_news}ê°œ")
        print(f"   â€¢ í‰ê·  ë‰´ìŠ¤: {(total_news/total_success):.1f}ê°œ/ì¢…ëª©" if total_success > 0 else "")
        
        # ì•„ëª¨ë ˆí¼ì‹œí”½ í™•ì¸
        amore_news = self.check_amorepacific_news()
        print(f"\\nğŸ¯ ì•„ëª¨ë ˆí¼ì‹œí”½ ë‰´ìŠ¤: {amore_news}ê°œ")
    
    def check_amorepacific_news(self):
        """ì•„ëª¨ë ˆí¼ì‹œí”½ ë‰´ìŠ¤ í™•ì¸"""
        try:
            with sqlite3.connect(self.news_db) as conn:
                cursor = conn.execute("""
                    SELECT COUNT(*) FROM news_articles 
                    WHERE stock_code = '090430' 
                       OR company_name LIKE '%ì•„ëª¨ë ˆí¼ì‹œí”½%'
                """)
                return cursor.fetchone()[0]
        except:
            return 0

def main():
    try:
        os.chdir('C:/data_analysis/value-investment-system/value-investment-system')
        collector = FullStocksNewsCollector()
        
        print("ğŸ”§ ìˆ˜ì§‘ ì˜µì…˜ ì„ íƒ:")
        print("1. í…ŒìŠ¤íŠ¸ (100ê°œ ì¢…ëª©)")
        print("2. ì¤‘ê°„ ê·œëª¨ (500ê°œ ì¢…ëª©)")  
        print("3. ì „ì²´ (3967ê°œ ì¢…ëª©) - ì•½ 2ì‹œê°„ ì†Œìš”")
        print("4. ì•„ëª¨ë ˆí¼ì‹œí”½ë§Œ")
        
        choice = input("ì„ íƒ (1-4, ê¸°ë³¸ê°’ 1): ").strip() or "1"
        
        if choice == "1":
            collector.collect_all_news_optimized(days_back=30, max_stocks=100)
        elif choice == "2":
            collector.collect_all_news_optimized(days_back=30, max_stocks=500)
        elif choice == "3":
            confirm = input("ì „ì²´ 3967ê°œ ì¢…ëª© ìˆ˜ì§‘ (ì•½ 2ì‹œê°„ ì†Œìš”)? (y/N): ").strip().lower()
            if confirm == 'y':
                collector.collect_all_news_optimized(days_back=30)
            else:
                print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif choice == "4":
            # ì•„ëª¨ë ˆí¼ì‹œí”½ë§Œ ìˆ˜ì§‘
            print("ğŸ¯ ì•„ëª¨ë ˆí¼ì‹œí”½ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
            stocks = [('090430', 'ì•„ëª¨ë ˆí¼ì‹œí”½')]
            
            total_success = 0
            total_news = 0
            
            for stock_code, company_name in stocks:
                print(f"\nğŸ“ˆ {company_name}({stock_code}) ì²˜ë¦¬ ì¤‘...")
                
                news_items = collector.search_latest_news(company_name, stock_code, 30)
                
                if news_items:
                    saved_count = collector.save_news_to_database(stock_code, company_name, news_items)
                    if saved_count > 0:
                        total_success += 1
                        total_news += saved_count
                        print(f"âœ… {saved_count}ê°œ ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ")
                    else:
                        print(f"âš ï¸ ëª¨ë‘ ì¤‘ë³µ ë‰´ìŠ¤")
                else:
                    print(f"âŒ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            print(f"\nğŸ‰ ì•„ëª¨ë ˆí¼ì‹œí”½ ìˆ˜ì§‘ ì™„ë£Œ: {total_news}ê°œ ë‰´ìŠ¤")
            
            # ê²°ê³¼ í™•ì¸
            amore_total = collector.check_amorepacific_news()
            print(f"ğŸ“Š ì•„ëª¨ë ˆí¼ì‹œí”½ ì´ ë‰´ìŠ¤: {amore_total}ê°œ")
        else:
            print("ê¸°ë³¸ê°’ìœ¼ë¡œ 100ê°œ ì¢…ëª© í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            collector.collect_all_news_optimized(days_back=30, max_stocks=100)
            
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
