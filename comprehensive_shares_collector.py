#!/usr/bin/env python3
"""
ì „ì²´ ì¢…ëª© ìƒì¥ì£¼ì‹ìˆ˜ ì¢…í•© ìˆ˜ì§‘ ì‹œìŠ¤í…œ

ë‹¤ì¤‘ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ë‚˜ë¨¸ì§€ 3,840ê°œ ì¢…ëª©ì˜ ìƒì¥ì£¼ì‹ìˆ˜ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

ë°ì´í„° ì†ŒìŠ¤:
1. KRX ê³µì‹ ë°ì´í„° (ìš°ì„ ìˆœìœ„ 1)
2. ë„¤ì´ë²„ ê¸ˆìœµ í¬ë¡¤ë§ (ìš°ì„ ìˆœìœ„ 2)  
3. ë‹¤ìŒ ê¸ˆìœµ í¬ë¡¤ë§ (ìš°ì„ ìˆœìœ„ 3)
4. ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ (ìš°ì„ ìˆœìœ„ 4)
5. ì¶”ì •ê°’ ê³„ì‚° (ìµœí›„ ìˆ˜ë‹¨)

ì‹¤í–‰ ë°©ë²•:
python comprehensive_shares_collector.py --method=all
python comprehensive_shares_collector.py --method=krx_only
python comprehensive_shares_collector.py --batch_size=50 --delay=0.1
"""

import sys
import sqlite3
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import re
from datetime import datetime
from pathlib import Path
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import json

# ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
try:
    import FinanceDataReader as fdr
    import yfinance as yf
except ImportError:
    print("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:")
    print("pip install finance-datareader yfinance")

class ComprehensiveSharesCollector:
    """ì¢…í•© ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘ ì‹œìŠ¤í…œ"""
    
    def __init__(self, batch_size=50, delay=0.1, max_workers=5):
        self.logger = self.setup_logging()
        self.db_path = Path('data/databases/stock_data.db')
        self.batch_size = batch_size
        self.delay = delay
        self.max_workers = max_workers
        
        # ì„¸ì…˜ ì„¤ì •
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        # í†µê³„ ì¶”ì 
        self.stats = {
            'total_missing': 0,
            'collected_krx': 0,
            'collected_naver': 0,
            'collected_daum': 0,
            'collected_yahoo': 0,
            'estimated': 0,
            'failed': 0,
            'start_time': None,
            'end_time': None
        }
        
        # ìºì‹œ
        self.krx_cache = {}
        self.failed_cache = set()
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('comprehensive_shares_collection.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    def get_missing_shares_stocks(self):
        """ìƒì¥ì£¼ì‹ìˆ˜ê°€ ì—†ëŠ” ì¢…ëª© ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                missing_stocks = pd.read_sql("""
                    SELECT stock_code, company_name, market_type
                    FROM company_info 
                    WHERE shares_outstanding IS NULL OR shares_outstanding = 0
                    ORDER BY 
                        CASE market_type 
                            WHEN 'KOSPI' THEN 1 
                            WHEN 'KOSDAQ' THEN 2 
                            WHEN 'KONEX' THEN 3 
                            ELSE 4 
                        END,
                        stock_code
                """, conn)
                
                self.stats['total_missing'] = len(missing_stocks)
                self.logger.info(f"ğŸ“‹ ìƒì¥ì£¼ì‹ìˆ˜ ì—†ëŠ” ì¢…ëª©: {len(missing_stocks):,}ê°œ")
                
                # ì‹œì¥ë³„ ë¶„í¬
                market_dist = missing_stocks['market_type'].value_counts()
                for market, count in market_dist.items():
                    self.logger.info(f"   {market}: {count:,}ê°œ")
                
                return missing_stocks
                
        except Exception as e:
            self.logger.error(f"âŒ ëˆ„ë½ ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def collect_from_krx_api(self, stock_codes):
        """KRX ê³µì‹ APIì—ì„œ ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘"""
        self.logger.info("ğŸ›ï¸ KRX ê³µì‹ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        collected_data = {}
        
        try:
            # KRX ìƒì¥ë²•ì¸ëª©ë¡ API í˜¸ì¶œ
            krx_url = "http://data.krx.co.kr/comm/bldAttendant/getJsonData.cmd"
            
            # KOSPI ë°ì´í„°
            kospi_payload = {
                'bld': 'dbms/MDC/STAT/standard/MDCSTAT01501',
                'mktId': 'STK',
                'trdDd': datetime.now().strftime('%Y%m%d'),
                'money': '1',
                'csvxls_isNo': 'false'
            }
            
            response = self.session.post(krx_url, data=kospi_payload, timeout=30)
            if response.status_code == 200:
                kospi_data = response.json()
                for item in kospi_data.get('OutBlock_1', []):
                    stock_code = item.get('ISU_SRT_CD', '').zfill(6)
                    shares = item.get('LIST_SHRS', 0)
                    
                    if stock_code and shares:
                        try:
                            shares_int = int(str(shares).replace(',', ''))
                            if shares_int > 0:
                                collected_data[stock_code] = {
                                    'shares': shares_int,
                                    'source': 'KRX_KOSPI',
                                    'company_name': item.get('ISU_ABBRV', '')
                                }
                        except:
                            continue
            
            # KOSDAQ ë°ì´í„°
            kosdaq_payload = {
                'bld': 'dbms/MDC/STAT/standard/MDCSTAT01501',
                'mktId': 'KSQ',
                'trdDd': datetime.now().strftime('%Y%m%d'),
                'money': '1',
                'csvxls_isNo': 'false'
            }
            
            response = self.session.post(krx_url, data=kosdaq_payload, timeout=30)
            if response.status_code == 200:
                kosdaq_data = response.json()
                for item in kosdaq_data.get('OutBlock_1', []):
                    stock_code = item.get('ISU_SRT_CD', '').zfill(6)
                    shares = item.get('LIST_SHRS', 0)
                    
                    if stock_code and shares:
                        try:
                            shares_int = int(str(shares).replace(',', ''))
                            if shares_int > 0:
                                collected_data[stock_code] = {
                                    'shares': shares_int,
                                    'source': 'KRX_KOSDAQ',
                                    'company_name': item.get('ISU_ABBRV', '')
                                }
                        except:
                            continue
            
            self.stats['collected_krx'] = len(collected_data)
            self.logger.info(f"âœ… KRX ë°ì´í„° ìˆ˜ì§‘: {len(collected_data):,}ê°œ")
            
            return collected_data
            
        except Exception as e:
            self.logger.error(f"âŒ KRX ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def collect_from_naver_finance(self, stock_code, company_name):
        """ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘"""
        try:
            url = f"https://finance.naver.com/item/main.naver?code={stock_code}"
            response = self.session.get(url, timeout=10)
            
            if response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ìƒì¥ì£¼ì‹ìˆ˜ ì°¾ê¸° (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
            patterns = [
                # íŒ¨í„´ 1: í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
                {'selector': '.sub_section table tr', 'text': 'ìƒì¥ì£¼ì‹ìˆ˜'},
                {'selector': '.section table tr', 'text': 'ìƒì¥ì£¼ì‹'},
                {'selector': '.tb_type1 tr', 'text': 'ìƒì¥ì£¼ì‹ìˆ˜'},
                # íŒ¨í„´ 2: ê¸°ì—…ê°œìš”ì—ì„œ ì°¾ê¸°
                {'selector': '.company_info tr', 'text': 'ìƒì¥ì£¼ì‹'},
                {'selector': '.info_table tr', 'text': 'ì£¼ì‹ìˆ˜'},
            ]
            
            for pattern in patterns:
                rows = soup.select(pattern['selector'])
                for row in rows:
                    if pattern['text'] in row.get_text():
                        # ìˆ«ì ì¶”ì¶œ
                        text = row.get_text()
                        numbers = re.findall(r'[\d,]+', text)
                        for num_str in numbers:
                            try:
                                num = int(num_str.replace(',', ''))
                                # ìƒì¥ì£¼ì‹ìˆ˜ ë²”ìœ„ ê²€ì¦ (10ë§Œ ~ 100ì–µì£¼)
                                if 100000 <= num <= 10000000000:
                                    return {
                                        'shares': num,
                                        'source': 'NAVER',
                                        'company_name': company_name
                                    }
                            except:
                                continue
            
            return None
            
        except Exception as e:
            return None
    
    def collect_from_daum_finance(self, stock_code, company_name):
        """ë‹¤ìŒ ê¸ˆìœµì—ì„œ ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘"""
        try:
            url = f"https://finance.daum.net/quotes/A{stock_code}"
            response = self.session.get(url, timeout=10)
            
            if response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ìƒì¥ì£¼ì‹ìˆ˜ ì°¾ê¸°
            info_items = soup.select('.info_major dl')
            for item in info_items:
                dt = item.find('dt')
                dd = item.find('dd')
                
                if dt and dd and 'ìƒì¥ì£¼ì‹ìˆ˜' in dt.get_text():
                    text = dd.get_text()
                    numbers = re.findall(r'[\d,]+', text)
                    for num_str in numbers:
                        try:
                            num = int(num_str.replace(',', ''))
                            if 100000 <= num <= 10000000000:
                                return {
                                    'shares': num,
                                    'source': 'DAUM',
                                    'company_name': company_name
                                }
                        except:
                            continue
            
            return None
            
        except Exception as e:
            return None
    
    def collect_from_yahoo_finance(self, stock_code, company_name):
        """ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ì—ì„œ ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘"""
        try:
            # í•œêµ­ ì¢…ëª©ì€ .KS ë˜ëŠ” .KQ ì ‘ë¯¸ì‚¬ í•„ìš”
            yahoo_symbol = f"{stock_code}.KS"  # KOSPI ê¸°ë³¸
            
            ticker = yf.Ticker(yahoo_symbol)
            info = ticker.info
            
            # ìƒì¥ì£¼ì‹ìˆ˜ í•„ë“œë“¤ í™•ì¸
            shares_fields = ['sharesOutstanding', 'impliedSharesOutstanding', 'floatShares']
            
            for field in shares_fields:
                if field in info and info[field]:
                    shares = info[field]
                    if isinstance(shares, (int, float)) and shares > 100000:
                        return {
                            'shares': int(shares),
                            'source': 'YAHOO',
                            'company_name': company_name
                        }
            
            # KOSDAQ ì‹œë„
            if not info or 'sharesOutstanding' not in info:
                yahoo_symbol = f"{stock_code}.KQ"
                ticker = yf.Ticker(yahoo_symbol)
                info = ticker.info
                
                for field in shares_fields:
                    if field in info and info[field]:
                        shares = info[field]
                        if isinstance(shares, (int, float)) and shares > 100000:
                            return {
                                'shares': int(shares),
                                'source': 'YAHOO_KQ',
                                'company_name': company_name
                            }
            
            return None
            
        except Exception as e:
            return None
    
    def estimate_shares_from_market_cap(self, stock_code, company_name, market_cap):
        """ì‹œê°€ì´ì•¡ì„ ì´ìš©í•œ ìƒì¥ì£¼ì‹ìˆ˜ ì¶”ì •"""
        try:
            # í˜„ì¬ê°€ ì¡°íšŒ
            current_price = self.get_current_price(stock_code)
            
            if current_price and current_price > 0 and market_cap and market_cap > 0:
                estimated_shares = int(market_cap / current_price)
                
                # í•©ë¦¬ì  ë²”ìœ„ ê²€ì¦
                if 100000 <= estimated_shares <= 10000000000:
                    return {
                        'shares': estimated_shares,
                        'source': 'ESTIMATED',
                        'company_name': company_name
                    }
            
            return None
            
        except Exception as e:
            return None
    
    def get_current_price(self, stock_code):
        """í˜„ì¬ê°€ ì¡°íšŒ"""
        try:
            end_date = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - pd.Timedelta(days=5)).strftime('%Y-%m-%d')
            
            data = fdr.DataReader(stock_code, start_date, end_date)
            
            if not data.empty:
                return float(data['Close'].iloc[-1])
            return None
            
        except Exception as e:
            return None
    
    def collect_single_stock_shares(self, stock_info):
        """ë‹¨ì¼ ì¢…ëª© ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘ (ë©€í‹°ì†ŒìŠ¤)"""
        stock_code = stock_info['stock_code']
        company_name = stock_info['company_name']
        market_type = stock_info.get('market_type', '')
        
        # ì‹¤íŒ¨ ìºì‹œ í™•ì¸
        if stock_code in self.failed_cache:
            return None
        
        # ìš°ì„ ìˆœìœ„ë³„ ìˆ˜ì§‘ ì‹œë„
        sources = [
            ('KRX', lambda: self.krx_cache.get(stock_code)),
            ('NAVER', lambda: self.collect_from_naver_finance(stock_code, company_name)),
            ('DAUM', lambda: self.collect_from_daum_finance(stock_code, company_name)),
            ('YAHOO', lambda: self.collect_from_yahoo_finance(stock_code, company_name)),
        ]
        
        for source_name, collect_func in sources:
            try:
                result = collect_func()
                if result and result.get('shares'):
                    self.logger.debug(f"âœ… {stock_code} {company_name}: {result['shares']:,}ì£¼ ({source_name})")
                    return {
                        'stock_code': stock_code,
                        'shares_outstanding': result['shares'],
                        'data_source': result['source']
                    }
                
                # API ì œí•œ ëŒ€ì‘
                time.sleep(self.delay)
                
            except Exception as e:
                self.logger.debug(f"âš ï¸ {stock_code} {source_name} ì‹¤íŒ¨: {e}")
                continue
        
        # ëª¨ë“  ì†ŒìŠ¤ ì‹¤íŒ¨ ì‹œ ì‹¤íŒ¨ ìºì‹œì— ì¶”ê°€
        self.failed_cache.add(stock_code)
        self.stats['failed'] += 1
        return None
    
    def batch_collect_shares(self, missing_stocks_df):
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘"""
        self.logger.info(f"ğŸš€ ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘: {len(missing_stocks_df):,}ê°œ ì¢…ëª©")
        
        # KRX ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ
        self.krx_cache = self.collect_from_krx_api(missing_stocks_df['stock_code'].tolist())
        
        collected_data = []
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for i in range(0, len(missing_stocks_df), self.batch_size):
            batch = missing_stocks_df.iloc[i:i+self.batch_size]
            
            self.logger.info(f"ğŸ“Š ë°°ì¹˜ {i//self.batch_size + 1}/{(len(missing_stocks_df)-1)//self.batch_size + 1} ì²˜ë¦¬ ì¤‘...")
            
            # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = []
                
                for _, stock_info in batch.iterrows():
                    future = executor.submit(self.collect_single_stock_shares, stock_info.to_dict())
                    futures.append(future)
                
                # ê²°ê³¼ ìˆ˜ì§‘
                for future in as_completed(futures):
                    try:
                        result = future.result(timeout=30)
                        if result:
                            collected_data.append(result)
                    except Exception as e:
                        self.logger.debug(f"Future ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        continue
            
            # ì§„í–‰ë¥  ì¶œë ¥
            progress = (i + self.batch_size) / len(missing_stocks_df) * 100
            collected_count = len(collected_data)
            self.logger.info(f"ì§„í–‰ë¥ : {progress:.1f}% ({collected_count:,}ê°œ ìˆ˜ì§‘)")
            
            # ë°°ì¹˜ ê°„ íœ´ì‹
            time.sleep(1)
        
        return collected_data
    
    def save_collected_shares(self, collected_data):
        """ìˆ˜ì§‘ëœ ìƒì¥ì£¼ì‹ìˆ˜ ë°ì´í„° ì €ì¥"""
        if not collected_data:
            self.logger.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                updated_count = 0
                
                for data in collected_data:
                    stock_code = data['stock_code']
                    shares = data['shares_outstanding']
                    source = data.get('data_source', 'UNKNOWN')
                    
                    conn.execute("""
                        UPDATE company_info 
                        SET shares_outstanding = ?, 
                            updated_at = ?,
                            data_source = ?
                        WHERE stock_code = ?
                    """, (
                        shares,
                        datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        source,
                        stock_code
                    ))
                    
                    updated_count += 1
                
                conn.commit()
                
            self.logger.info(f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {updated_count:,}ê°œ ì¢…ëª©")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def generate_collection_report(self):
        """ìˆ˜ì§‘ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        self.stats['end_time'] = datetime.now()
        duration = (self.stats['end_time'] - self.stats['start_time']).total_seconds() / 60
        
        print("\n" + "="*80)
        print("ğŸ“Š ì „ì²´ ì¢…ëª© ìƒì¥ì£¼ì‹ìˆ˜ ìˆ˜ì§‘ ì™„ë£Œ ë¦¬í¬íŠ¸")
        print("="*80)
        
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {duration:.1f}ë¶„")
        print(f"ğŸ“‹ ì´ ëŒ€ìƒ ì¢…ëª©: {self.stats['total_missing']:,}ê°œ")
        print()
        
        total_collected = (self.stats['collected_krx'] + self.stats['collected_naver'] + 
                          self.stats['collected_daum'] + self.stats['collected_yahoo'] + 
                          self.stats['estimated'])
        
        print("ğŸ“ˆ ì†ŒìŠ¤ë³„ ìˆ˜ì§‘ í˜„í™©:")
        print(f"   ğŸ›ï¸ KRX ê³µì‹: {self.stats['collected_krx']:,}ê°œ")
        print(f"   ğŸŒ ë„¤ì´ë²„: {self.stats['collected_naver']:,}ê°œ")
        print(f"   ğŸ” ë‹¤ìŒ: {self.stats['collected_daum']:,}ê°œ")
        print(f"   ğŸ“Š ì•¼í›„: {self.stats['collected_yahoo']:,}ê°œ")
        print(f"   ğŸ§® ì¶”ì •ê°’: {self.stats['estimated']:,}ê°œ")
        print(f"   âŒ ì‹¤íŒ¨: {self.stats['failed']:,}ê°œ")
        print()
        
        success_rate = (total_collected / self.stats['total_missing'] * 100) if self.stats['total_missing'] > 0 else 0
        print(f"âœ… ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({total_collected:,}/{self.stats['total_missing']:,})")
        
        # ìµœì¢… ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
        self.check_final_database_status()
    
    def check_final_database_status(self):
        """ìµœì¢… ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                stats = pd.read_sql("""
                    SELECT 
                        COUNT(*) as total_stocks,
                        COUNT(CASE WHEN shares_outstanding IS NOT NULL AND shares_outstanding > 0 THEN 1 END) as has_shares,
                        COUNT(CASE WHEN market_cap IS NOT NULL AND market_cap > 0 THEN 1 END) as has_market_cap
                    FROM company_info
                """, conn).iloc[0]
                
                print("\nğŸ“Š ìµœì¢… ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:")
                print(f"   ì „ì²´ ì¢…ëª©: {stats['total_stocks']:,}ê°œ")
                print(f"   ìƒì¥ì£¼ì‹ìˆ˜ ìˆìŒ: {stats['has_shares']:,}ê°œ ({stats['has_shares']/stats['total_stocks']*100:.1f}%)")
                print(f"   ì‹œê°€ì´ì•¡ ìˆìŒ: {stats['has_market_cap']:,}ê°œ ({stats['has_market_cap']/stats['total_stocks']*100:.1f}%)")
                
                # ìƒìœ„ ì¢…ëª©ë“¤ í™•ì¸
                top_stocks = pd.read_sql("""
                    SELECT stock_code, company_name, market_cap, shares_outstanding, market_type
                    FROM company_info 
                    WHERE market_cap IS NOT NULL AND market_cap > 0
                    ORDER BY market_cap DESC 
                    LIMIT 10
                """, conn)
                
                if not top_stocks.empty:
                    print("\nğŸ† ì‹œê°€ì´ì•¡ ìƒìœ„ 10ê°œ ì¢…ëª©:")
                    for i, row in top_stocks.iterrows():
                        market_cap_trillion = row['market_cap'] / 1e12
                        shares_million = row['shares_outstanding'] / 1e6 if row['shares_outstanding'] else 0
                        print(f"   {i+1:2d}. {row['stock_code']} {row['company_name']} ({row['market_type']}) - {market_cap_trillion:.1f}ì¡° ({shares_million:.0f}Mì£¼)")
                
        except Exception as e:
            print(f"âŒ ìµœì¢… ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def run_comprehensive_collection(self, method='all'):
        """ì¢…í•© ìˆ˜ì§‘ ì‹¤í–‰"""
        self.stats['start_time'] = datetime.now()
        
        print("ğŸš€ ì „ì²´ ì¢…ëª© ìƒì¥ì£¼ì‹ìˆ˜ ì¢…í•© ìˆ˜ì§‘ ì‹œì‘")
        print("="*80)
        
        # 1. ëˆ„ë½ ì¢…ëª© ì¡°íšŒ
        missing_stocks = self.get_missing_shares_stocks()
        
        if missing_stocks.empty:
            print("âœ… ëª¨ë“  ì¢…ëª©ì˜ ìƒì¥ì£¼ì‹ìˆ˜ê°€ ì´ë¯¸ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
        
        # 2. ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤í–‰
        collected_data = self.batch_collect_shares(missing_stocks)
        
        # 3. ë°ì´í„° ì €ì¥
        if collected_data:
            self.save_collected_shares(collected_data)
        
        # 4. ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_collection_report()
        
        return True


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì „ì²´ ì¢…ëª© ìƒì¥ì£¼ì‹ìˆ˜ ì¢…í•© ìˆ˜ì§‘ ì‹œìŠ¤í…œ')
    parser.add_argument('--method', choices=['all', 'krx_only', 'web_only'], default='all', help='ìˆ˜ì§‘ ë°©ë²•')
    parser.add_argument('--batch_size', type=int, default=50, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--delay', type=float, default=0.1, help='API í˜¸ì¶œ ê°„ ì§€ì—°ì‹œê°„(ì´ˆ)')
    parser.add_argument('--max_workers', type=int, default=5, help='ìµœëŒ€ ë™ì‹œ ì‘ì—… ìˆ˜')
    parser.add_argument('--test_mode', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (10ê°œ ì¢…ëª©ë§Œ)')
    
    args = parser.parse_args()
    
    try:
        collector = ComprehensiveSharesCollector(
            batch_size=args.batch_size,
            delay=args.delay,
            max_workers=args.max_workers
        )
        
        if args.test_mode:
            collector.batch_size = 10
            print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: 10ê°œ ì¢…ëª©ë§Œ ì²˜ë¦¬")
        
        success = collector.run_comprehensive_collection(method=args.method)
        
        if success:
            print("\nâœ… ì „ì²´ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
            print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
            print("1. python forecast_data_analyzer_fixed.py --check_db  # ê²°ê³¼ í™•ì¸")
            print("2. python forecast_data_analyzer_fixed.py --collect_top 20  # ëŒ€í˜•ì£¼ ì¶”ì •ì‹¤ì  ìˆ˜ì§‘")
        else:
            print("\nâŒ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
        print("ì§„í–‰ëœ ë°ì´í„°ëŠ” ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    return True


if __name__ == "__main__":
    main()