"""
ë©”ëª¨ë¦¬ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
"""

import gc
import psutil
import os
import sys
import threading
import time
from typing import Dict, List, Optional, Any, Callable
from functools import wraps
from contextlib import contextmanager
import logging
import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)

class MemoryMonitor:
    """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.process = psutil.Process(os.getpid())
        self.initial_memory = self.get_memory_usage()
        
    def get_memory_usage(self) -> Dict[str, float]:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
        try:
            memory_info = self.process.memory_info()
            virtual_memory = psutil.virtual_memory()
            
            return {
                'rss': memory_info.rss / 1024 / 1024,  # MB
                'vms': memory_info.vms / 1024 / 1024,  # MB
                'percent': self.process.memory_percent(),
                'available': virtual_memory.available / 1024 / 1024,  # MB
                'total': virtual_memory.total / 1024 / 1024,  # MB
                'used': virtual_memory.used / 1024 / 1024,  # MB
                'free': virtual_memory.free / 1024 / 1024,  # MB
            }
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_memory_info(self) -> Dict[str, Any]:
        """ìƒì„¸í•œ ë©”ëª¨ë¦¬ ì •ë³´ ë°˜í™˜"""
        try:
            usage = self.get_memory_usage()
            
            return {
                'current_usage': usage,
                'peak_usage': self.process.memory_info().peak_wset / 1024 / 1024 if hasattr(self.process.memory_info(), 'peak_wset') else 0,
                'memory_increase': usage.get('rss', 0) - self.initial_memory.get('rss', 0),
                'gc_stats': {
                    'collections': gc.get_stats(),
                    'count': gc.get_count(),
                    'threshold': gc.get_threshold()
                }
            }
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def print_memory_info(self):
        """ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥"""
        info = self.get_memory_info()
        usage = info.get('current_usage', {})
        
        print("ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´")
        print("=" * 40)
        print(f"RSS (ë¬¼ë¦¬ ë©”ëª¨ë¦¬): {usage.get('rss', 0):.2f} MB")
        print(f"VMS (ê°€ìƒ ë©”ëª¨ë¦¬): {usage.get('vms', 0):.2f} MB")
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {usage.get('percent', 0):.2f}%")
        print(f"ì‹œìŠ¤í…œ ì „ì²´ ë©”ëª¨ë¦¬: {usage.get('total', 0):.2f} MB")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {usage.get('available', 0):.2f} MB")
        print(f"ì´ˆê¸° ëŒ€ë¹„ ë©”ëª¨ë¦¬ ì¦ê°€: {info.get('memory_increase', 0):.2f} MB")
        
        gc_stats = info.get('gc_stats', {})
        gc_count = gc_stats.get('count', [0, 0, 0])
        print(f"GC ì¹´ìš´íŠ¸: Gen0={gc_count[0]}, Gen1={gc_count[1]}, Gen2={gc_count[2]}")

class MemoryOptimizer:
    """ë©”ëª¨ë¦¬ ìµœì í™” í´ë˜ìŠ¤"""
    
    @staticmethod
    def optimize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            original_memory = df.memory_usage(deep=True).sum()
            optimized_df = df.copy()
            
            # ìˆ«ì íƒ€ì… ìµœì í™”
            for col in optimized_df.select_dtypes(include=['int']).columns:
                col_min = optimized_df[col].min()
                col_max = optimized_df[col].max()
                
                if col_min >= -128 and col_max <= 127:
                    optimized_df[col] = optimized_df[col].astype('int8')
                elif col_min >= -32768 and col_max <= 32767:
                    optimized_df[col] = optimized_df[col].astype('int16')
                elif col_min >= -2147483648 and col_max <= 2147483647:
                    optimized_df[col] = optimized_df[col].astype('int32')
            
            # ì‹¤ìˆ˜ íƒ€ì… ìµœì í™”
            for col in optimized_df.select_dtypes(include=['float']).columns:
                optimized_df[col] = pd.to_numeric(optimized_df[col], downcast='float')
            
            # ë¬¸ìì—´ íƒ€ì… ìµœì í™”
            for col in optimized_df.select_dtypes(include=['object']).columns:
                if optimized_df[col].nunique() / len(optimized_df) < 0.5:
                    optimized_df[col] = optimized_df[col].astype('category')
            
            # ë‚ ì§œ íƒ€ì… ìµœì í™”
            for col in optimized_df.columns:
                if 'date' in col.lower() or 'time' in col.lower():
                    try:
                        optimized_df[col] = pd.to_datetime(optimized_df[col], errors='ignore')
                    except:
                        pass
            
            optimized_memory = optimized_df.memory_usage(deep=True).sum()
            reduction = (original_memory - optimized_memory) / original_memory * 100
            
            logger.info(f"ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {reduction:.2f}% ê°ì†Œ")
            
            return optimized_df
        except Exception as e:
            logger.error(f"ë°ì´í„°í”„ë ˆì„ ìµœì í™” ì‹¤íŒ¨: {e}")
            return df
    
    @staticmethod
    def clear_memory():
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
            gc.collect()
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(pd, 'core'):
                pd.core.common.clear_cache()
            
            logger.info("ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    @staticmethod
    def optimize_numpy_array(arr: np.ndarray) -> np.ndarray:
        """NumPy ë°°ì—´ ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            if arr.dtype == np.float64:
                # float32ë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
                if np.allclose(arr, arr.astype(np.float32)):
                    return arr.astype(np.float32)
            
            elif arr.dtype == np.int64:
                # ë” ì‘ì€ int íƒ€ì…ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
                if arr.min() >= -128 and arr.max() <= 127:
                    return arr.astype(np.int8)
                elif arr.min() >= -32768 and arr.max() <= 32767:
                    return arr.astype(np.int16)
                elif arr.min() >= -2147483648 and arr.max() <= 2147483647:
                    return arr.astype(np.int32)
            
            return arr
        except Exception as e:
            logger.error(f"NumPy ë°°ì—´ ìµœì í™” ì‹¤íŒ¨: {e}")
            return arr
    
    @staticmethod
    def batch_process(data: List[Any], batch_size: int = 1000,
                     processor: Callable = None) -> List[Any]:
        """ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        if processor is None:
            processor = lambda x: x
        
        results = []
        
        try:
            for i in range(0, len(data), batch_size):
                batch = data[i:i + batch_size]
                batch_result = processor(batch)
                results.extend(batch_result if isinstance(batch_result, list) else [batch_result])
                
                # ë°°ì¹˜ ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
                if i % (batch_size * 10) == 0:
                    gc.collect()
            
            return results
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return data

class MemoryCache:
    """ë©”ëª¨ë¦¬ ìºì‹œ í´ë˜ìŠ¤"""
    
    def __init__(self, max_size: int = 100, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self.cache = {}
        self.access_times = {}
        self.lock = threading.Lock()
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        with self.lock:
            if key in self.cache:
                # TTL í™•ì¸
                if time.time() - self.access_times[key] < self.ttl:
                    self.access_times[key] = time.time()
                    return self.cache[key]
                else:
                    # ë§Œë£Œëœ í•­ëª© ì œê±°
                    del self.cache[key]
                    del self.access_times[key]
        
        return None
    
    def set(self, key: str, value: Any):
        """ìºì‹œì— ê°’ ì €ì¥"""
        with self.lock:
            # ìºì‹œ í¬ê¸° í™•ì¸
            if len(self.cache) >= self.max_size:
                self._evict_oldest()
            
            self.cache[key] = value
            self.access_times[key] = time.time()
    
    def _evict_oldest(self):
        """ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°"""
        if not self.access_times:
            return
        
        oldest_key = min(self.access_times, key=self.access_times.get)
        del self.cache[oldest_key]
        del self.access_times[oldest_key]
    
    def clear(self):
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        with self.lock:
            self.cache.clear()
            self.access_times.clear()
    
    def size(self) -> int:
        """ìºì‹œ í¬ê¸° ë°˜í™˜"""
        return len(self.cache)
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        with self.lock:
            return {
                'size': len(self.cache),
                'max_size': self.max_size,
                'ttl': self.ttl,
                'keys': list(self.cache.keys())
            }

# ë°ì½”ë ˆì´í„°ë“¤
def memory_monitor(func):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        monitor = MemoryMonitor()
        initial_memory = monitor.get_memory_usage()
        
        logger.info(f"í•¨ìˆ˜ '{func.__name__}' ì‹¤í–‰ ì „ ë©”ëª¨ë¦¬: {initial_memory.get('rss', 0):.2f} MB")
        
        try:
            result = func(*args, **kwargs)
            
            final_memory = monitor.get_memory_usage()
            memory_diff = final_memory.get('rss', 0) - initial_memory.get('rss', 0)
            
            logger.info(f"í•¨ìˆ˜ '{func.__name__}' ì‹¤í–‰ í›„ ë©”ëª¨ë¦¬: {final_memory.get('rss', 0):.2f} MB (ì°¨ì´: {memory_diff:+.2f} MB)")
            
            return result
        except Exception as e:
            logger.error(f"í•¨ìˆ˜ '{func.__name__}' ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    return wrapper

def memory_limit(max_memory_mb: int = 1000):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            monitor = MemoryMonitor()
            current_memory = monitor.get_memory_usage()
            
            if current_memory.get('rss', 0) > max_memory_mb:
                logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì´ˆê³¼: {current_memory.get('rss', 0):.2f} MB > {max_memory_mb} MB")
                MemoryOptimizer.clear_memory()
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ë‹¤ì‹œ í™•ì¸
                current_memory = monitor.get_memory_usage()
                if current_memory.get('rss', 0) > max_memory_mb:
                    raise MemoryError(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: {current_memory.get('rss', 0):.2f} MB")
            
            return func(*args, **kwargs)
        
        return wrapper
    return decorator

def auto_cleanup(func):
    """ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            MemoryOptimizer.clear_memory()
    
    return wrapper

# ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
@contextmanager
def memory_context(max_memory_mb: int = 1000):
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    monitor = MemoryMonitor()
    initial_memory = monitor.get_memory_usage()
    
    try:
        yield monitor
    finally:
        final_memory = monitor.get_memory_usage()
        memory_diff = final_memory.get('rss', 0) - initial_memory.get('rss', 0)
        
        if memory_diff > max_memory_mb * 0.5:  # 50% ì´ìƒ ì¦ê°€ ì‹œ
            logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í¬ê²Œ ì¦ê°€: {memory_diff:.2f} MB")
            MemoryOptimizer.clear_memory()

# ì „ì—­ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ë° ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
memory_monitor_instance = MemoryMonitor()
memory_cache = MemoryCache()

# í¸ì˜ í•¨ìˆ˜ë“¤
def get_memory_usage() -> Dict[str, float]:
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
    return memory_monitor_instance.get_memory_usage()

def print_memory_info():
    """ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥"""
    memory_monitor_instance.print_memory_info()

def optimize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ìµœì í™”"""
    return MemoryOptimizer.optimize_dataframe(df)

def clear_memory():
    """ë©”ëª¨ë¦¬ ì •ë¦¬"""
    MemoryOptimizer.clear_memory()

def cache_get(key: str) -> Optional[Any]:
    """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
    return memory_cache.get(key)

def cache_set(key: str, value: Any):
    """ìºì‹œì— ê°’ ì €ì¥"""
    memory_cache.set(key, value)

def cache_clear():
    """ìºì‹œ ì „ì²´ ì‚­ì œ"""
    memory_cache.clear()

def get_cache_stats() -> Dict[str, Any]:
    """ìºì‹œ í†µê³„ ë°˜í™˜"""
    return memory_cache.get_stats()

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
    print("ğŸ“Š ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸:")
    print_memory_info()
    
    # ë°ì´í„°í”„ë ˆì„ ìµœì í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ“ˆ ë°ì´í„°í”„ë ˆì„ ìµœì í™” í…ŒìŠ¤íŠ¸:")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = pd.DataFrame({
        'int_col': np.random.randint(1, 100, 1000),
        'float_col': np.random.random(1000),
        'str_col': np.random.choice(['A', 'B', 'C'], 1000),
        'date_col': pd.date_range('2024-01-01', periods=1000)
    })
    
    print(f"ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬: {test_data.memory_usage(deep=True).sum() / 1024:.2f} KB")
    
    optimized_df = optimize_dataframe(test_data)
    print(f"ìµœì í™”ëœ ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬: {optimized_df.memory_usage(deep=True).sum() / 1024:.2f} KB")
    
    # ìºì‹œ í…ŒìŠ¤íŠ¸
    print("\nğŸ’¾ ìºì‹œ í…ŒìŠ¤íŠ¸:")
    cache_set('test_key', 'test_value')
    cached_value = cache_get('test_key')
    print(f"ìºì‹œëœ ê°’: {cached_value}")
    
    cache_stats = get_cache_stats()
    print(f"ìºì‹œ í†µê³„: {cache_stats}")
    
    # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
    print("\nğŸ”„ ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸:")
    with memory_context(max_memory_mb=500) as monitor:
        # ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ëŠ” ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        large_data = np.random.random((1000, 1000))
        current_usage = monitor.get_memory_usage()
        print(f"ì»¨í…ìŠ¤íŠ¸ ë‚´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {current_usage.get('rss', 0):.2f} MB")
    
    # ë°ì½”ë ˆì´í„° í…ŒìŠ¤íŠ¸
    print("\nâš¡ ë°ì½”ë ˆì´í„° í…ŒìŠ¤íŠ¸:")
    
    @memory_monitor
    @auto_cleanup
    def test_function():
        """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
        data = np.random.random((100, 100))
        df = pd.DataFrame(data)
        return df.sum().sum()
    
    result = test_function()
    print(f"í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ê²°ê³¼: {result:.2f}")
    
    # ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("\nğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:")
    large_list = list(range(10000))
    
    def square_batch(batch):
        return [x**2 for x in batch]
    
    squared_results = MemoryOptimizer.batch_process(large_list, batch_size=1000, processor=square_batch)
    print(f"ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ê¸¸ì´: {len(squared_results)}")
    
    # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
    print("\nğŸ ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ:")
    print_memory_info()
    
    print("\nâœ… ëª¨ë“  ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")