#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì „ ì¢…ëª© ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ëŒ€ëŸ‰ ë¶„ì„ ì‹œìŠ¤í…œ
ì„±ê³µ í™•ì¸ëœ buffett_final_analyzer ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ì¢…ëª© ë¶„ì„
"""

import sqlite3
import pandas as pd
import numpy as np
import warnings
import sys
import os
from datetime import datetime
import logging
from pathlib import Path
import time
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from buffett_final_analyzer import BuffettFinalAnalyzer

warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/buffett_all_stocks_batch.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BuffettBatchAnalyzer:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.analyzer = BuffettFinalAnalyzer()
        self.results = []
        self.failed_stocks = []
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.results_dir = Path("results/buffett_analysis")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # í†µê³„
        self.stats = {
            'total_analyzed': 0,
            'successful': 0,
            'failed': 0,
            'start_time': None,
            'end_time': None
        }
    
    def create_results_table(self):
        """ê²°ê³¼ ì €ì¥ í…Œì´ë¸” ìƒì„± (í™•ì¥ëœ ë²„ì „)"""
        try:
            conn = sqlite3.connect("data/databases/buffett_scorecard.db")
            
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS buffett_all_stocks_final (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                stock_code TEXT NOT NULL,
                company_name TEXT NOT NULL,
                analysis_date TEXT NOT NULL,
                
                -- ê¸°ë³¸ ì ìˆ˜ ì •ë³´
                total_score REAL,
                grade TEXT,
                investment_grade TEXT,
                risk_level TEXT,
                quality_rating TEXT,
                
                -- ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ (110ì  ë§Œì )
                profitability_score REAL,
                growth_score REAL,
                stability_score REAL,
                efficiency_score REAL,
                valuation_score REAL,
                quality_premium_score REAL,
                
                -- ì¬ë¬´ ë¹„ìœ¨
                roe REAL,
                roa REAL,
                debt_ratio REAL,
                current_ratio REAL,
                pe_ratio REAL,
                pb_ratio REAL,
                net_margin REAL,
                operating_margin REAL,
                
                -- ëª©í‘œê°€ ì •ë³´
                target_price_low REAL,
                target_price_high REAL,
                current_price REAL,
                upside_potential REAL,
                
                -- ë©”íƒ€ ì •ë³´
                analysis_status TEXT,
                error_message TEXT,
                
                -- íƒ€ì„ìŠ¤íƒ¬í”„
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                -- ìœ ë‹ˆí¬ ì œì•½
                UNIQUE(stock_code, analysis_date)
            )
            """
            
            conn.execute(create_table_sql)
            conn.commit()
            conn.close()
            
            logger.info("âœ… ì „ì²´ ì¢…ëª© ê²°ê³¼ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
    
    def save_results_to_database(self):
        """ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        if not self.results:
            logger.warning("âš ï¸ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            conn = sqlite3.connect("data/databases/buffett_scorecard.db")
            
            # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            today = datetime.now().strftime('%Y-%m-%d')
            delete_count = conn.execute(
                "DELETE FROM buffett_all_stocks_final WHERE analysis_date = ?", 
                (today,)
            ).rowcount
            
            if delete_count > 0:
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {delete_count}ê±´")
            
            # ìƒˆ ê²°ê³¼ ì €ì¥
            df = pd.DataFrame(self.results)
            df.to_sql('buffett_all_stocks_final', conn, if_exists='append', index=False)
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {len(self.results)}ê±´")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def save_results_to_files(self):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not self.results:
            logger.warning("âš ï¸ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            df = pd.DataFrame(self.results)
            df_sorted = df.sort_values('total_score', ascending=False)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # 1. ì „ì²´ ê²°ê³¼ CSV
            csv_file = self.results_dir / f"buffett_all_stocks_{timestamp}.csv"
            df_sorted.to_csv(csv_file, index=False, encoding='utf-8-sig')
            
            # 2. Top 100 JSON
            top100 = df_sorted.head(100)
            json_file = self.results_dir / f"buffett_top100_{timestamp}.json"
            top100.to_json(json_file, orient='records', indent=2, force_ascii=False)
            
            # 3. íˆ¬ì ì¶”ì²œ ì¢…ëª© (Buy ì´ìƒ)
            buy_stocks = df_sorted[df_sorted['investment_grade'].isin(['Strong Buy', 'Buy'])]
            if len(buy_stocks) > 0:
                buy_file = self.results_dir / f"buffett_buy_recommendations_{timestamp}.csv"
                buy_stocks.to_csv(buy_file, index=False, encoding='utf-8-sig')
                logger.info(f"ğŸ’° íˆ¬ì ì¶”ì²œ ì¢…ëª©: {len(buy_stocks)}ê°œ â†’ {buy_file}")
            
            # 4. ë“±ê¸‰ë³„ ë¶„ë¥˜
            for grade in ['A+', 'A', 'A-', 'B+', 'B']:
                grade_stocks = df_sorted[df_sorted['grade'] == grade]
                if len(grade_stocks) > 0:
                    grade_file = self.results_dir / f"buffett_grade_{grade.replace('+', 'plus').replace('-', 'minus')}_{timestamp}.csv"
                    grade_stocks.to_csv(grade_file, index=False, encoding='utf-8-sig')
            
            logger.info(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ:")
            logger.info(f"   ğŸ“Š ì „ì²´ ê²°ê³¼: {csv_file}")
            logger.info(f"   ğŸ† Top 100: {json_file}")
            
            return csv_file, json_file
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None, None
    
    def generate_comprehensive_report(self):
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if not self.results:
            return
        
        try:
            df = pd.DataFrame(self.results)
            df_sorted = df.sort_values('total_score', ascending=False)
            
            # ê¸°ë³¸ í†µê³„
            total_count = len(df)
            avg_score = df['total_score'].mean()
            std_score = df['total_score'].std()
            max_score = df['total_score'].max()
            min_score = df['total_score'].min()
            
            # ë“±ê¸‰ë³„ ë¶„í¬
            grade_dist = df['grade'].value_counts().sort_index()
            
            # íˆ¬ìë“±ê¸‰ë³„ ë¶„í¬
            investment_dist = df['investment_grade'].value_counts()
            
            # ë¦¬ìŠ¤í¬ë³„ ë¶„í¬
            risk_dist = df['risk_level'].value_counts()
            
            # Top 20
            top20 = df_sorted.head(20)[['company_name', 'stock_code', 'total_score', 'grade', 'investment_grade']]
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            if self.stats['start_time'] and self.stats['end_time']:
                elapsed_time = (self.stats['end_time'] - self.stats['start_time']).total_seconds()
                elapsed_minutes = elapsed_time / 60
            else:
                elapsed_minutes = 0
            
            # ë³´ê³ ì„œ ìƒì„±
            report = f"""
ğŸ¯ ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ì „ì²´ ì¢…ëª© ë¶„ì„ ê²°ê³¼ ë³´ê³ ì„œ
{'='*80}
ğŸ“… ë¶„ì„ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â±ï¸ ë¶„ì„ ì†Œìš”ì‹œê°„: {elapsed_minutes:.1f}ë¶„
ğŸ“Š ë¶„ì„ í˜„í™©:
   - ì „ì²´ ë¶„ì„ ì‹œë„: {self.stats['total_analyzed']:,}ê°œ ì¢…ëª©
   - ì„±ê³µ: {self.stats['successful']:,}ê°œ ({self.stats['successful']/max(1, self.stats['total_analyzed'])*100:.1f}%)
   - ì‹¤íŒ¨: {self.stats['failed']:,}ê°œ ({self.stats['failed']/max(1, self.stats['total_analyzed'])*100:.1f}%)

ğŸ“ˆ ì ìˆ˜ í†µê³„:
   - í‰ê·  ì ìˆ˜: {avg_score:.1f}/110ì 
   - í‘œì¤€í¸ì°¨: {std_score:.1f}ì 
   - ìµœê³  ì ìˆ˜: {max_score:.1f}/110ì  ({df_sorted.iloc[0]['company_name']})
   - ìµœì € ì ìˆ˜: {min_score:.1f}/110ì  ({df_sorted.iloc[-1]['company_name']})

ğŸ† ë“±ê¸‰ë³„ ë¶„í¬:
{grade_dist.to_string()}

ğŸ’° íˆ¬ìë“±ê¸‰ë³„ ë¶„í¬:
{investment_dist.to_string()}

âš ï¸ ë¦¬ìŠ¤í¬ë³„ ë¶„í¬:
{risk_dist.to_string()}

ğŸ¥‡ Top 20 ì¢…ëª©:
{top20.to_string(index=False)}

ğŸ“Š ì£¼ìš” í†µê³„:
   - Aë“±ê¸‰ ì´ìƒ (85ì +): {len(df[df['total_score'] >= 85])}ê°œ ({len(df[df['total_score'] >= 85])/total_count*100:.1f}%)
   - B+ë“±ê¸‰ ì´ìƒ (75ì +): {len(df[df['total_score'] >= 75])}ê°œ ({len(df[df['total_score'] >= 75])/total_count*100:.1f}%)
   - íˆ¬ì ì¶”ì²œ (Buy ì´ìƒ): {len(df[df['investment_grade'].isin(['Strong Buy', 'Buy'])])}ê°œ
   - ì €ìœ„í—˜ ì¢…ëª© (Low Risk ì´í•˜): {len(df[df['risk_level'].isin(['Very Low', 'Low'])])}ê°œ

ğŸ’¡ íˆ¬ì ì¸ì‚¬ì´íŠ¸:
   - ìµœê³  ìˆ˜ìµì„± ì¢…ëª©: {df.loc[df['profitability_score'].idxmax(), 'company_name']} ({df['profitability_score'].max():.1f}/30ì )
   - ìµœê³  ì„±ì¥ì„± ì¢…ëª©: {df.loc[df['growth_score'].idxmax(), 'company_name']} ({df['growth_score'].max():.1f}/25ì )
   - ìµœê³  ì•ˆì •ì„± ì¢…ëª©: {df.loc[df['stability_score'].idxmax(), 'company_name']} ({df['stability_score'].max():.1f}/25ì )
   - ìµœê³  ê°€ì¹˜í‰ê°€ ì¢…ëª©: {df.loc[df['valuation_score'].idxmax(), 'company_name']} ({df['valuation_score'].max():.1f}/20ì )

{'='*80}
"""
            
            print(report)
            
            # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_file = self.results_dir / f"buffett_comprehensive_report_{timestamp}.txt"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            logger.info(f"ğŸ“„ ì¢…í•© ë³´ê³ ì„œ ì €ì¥: {report_file}")
            
        except Exception as e:
            logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def run_batch_analysis(self, max_stocks=None, save_interval=100):
        """ì „ì²´ ì¢…ëª© ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰"""
        logger.info("ğŸš€ ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ì „ì²´ ì¢…ëª© ë°°ì¹˜ ë¶„ì„ ì‹œì‘")
        logger.info("=" * 80)
        
        self.stats['start_time'] = datetime.now()
        
        try:
            # 1. í…Œì´ë¸” ìƒì„±
            self.create_results_table()
            
            # 2. ë¶„ì„ ëŒ€ìƒ ì¢…ëª© ì¡°íšŒ
            stocks_df = self.analyzer.get_all_stocks_safe()
            
            if stocks_df.empty:
                logger.error("âŒ ë¶„ì„í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ìµœëŒ€ ë¶„ì„ ìˆ˜ ì œí•œ
            if max_stocks:
                stocks_df = stocks_df.head(max_stocks)
                logger.info(f"ğŸ”§ ì œí•œ ëª¨ë“œ: ìƒìœ„ {max_stocks}ê°œ ì¢…ëª©ë§Œ ë¶„ì„")
            
            total_stocks = len(stocks_df)
            self.stats['total_analyzed'] = total_stocks
            
            logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {total_stocks:,}ê°œ ì¢…ëª©")
            logger.info(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì£¼ê¸°: {save_interval}ê°œë§ˆë‹¤")
            
            # 3. ê° ì¢…ëª© ë¶„ì„
            for idx, row in stocks_df.iterrows():
                try:
                    stock_code = row['stock_code']
                    company_name = row['company_name']
                    
                    progress = (idx + 1) / total_stocks * 100
                    
                    # ì§„í–‰ë¥  ì¶œë ¥ (10ê°œë§ˆë‹¤)
                    if (idx + 1) % 10 == 0 or idx == 0:
                        logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% ({idx+1:,}/{total_stocks:,}) - {company_name}")
                    
                    # ê°œë³„ ì¢…ëª© ë¶„ì„
                    result = self.analyzer.analyze_single_stock(stock_code, company_name)
                    
                    if result and result.get('analysis_status', '').startswith('SUCCESS'):
                        self.results.append(result)
                        self.stats['successful'] += 1
                        
                        # ê°„ë‹¨í•œ ê²°ê³¼ ë¡œê·¸ (50ê°œë§ˆë‹¤)
                        if (idx + 1) % 50 == 0:
                            logger.info(f"âœ… {company_name}: {result['total_score']:.1f}ì , {result['grade']}")
                    else:
                        self.failed_stocks.append({
                            'stock_code': stock_code,
                            'company_name': company_name,
                            'error': result.get('error_message', 'Unknown error')
                        })
                        self.stats['failed'] += 1
                        
                        if (idx + 1) % 50 == 0:
                            logger.warning(f"âŒ {company_name}: ë¶„ì„ ì‹¤íŒ¨")
                    
                    # ì¤‘ê°„ ì €ì¥
                    if (idx + 1) % save_interval == 0 and self.results:
                        logger.info(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥: {len(self.results)}ê±´")
                        self.save_results_to_database()
                    
                    # ì‹œìŠ¤í…œ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                    time.sleep(0.01)
                    
                except KeyboardInterrupt:
                    logger.warning("âš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­")
                    break
                except Exception as e:
                    logger.error(f"âŒ ì¢…ëª© ë¶„ì„ ì˜¤ë¥˜: {row.get('company_name', 'Unknown')} - {str(e)}")
                    self.stats['failed'] += 1
                    continue
            
            self.stats['end_time'] = datetime.now()
            
            # 4. ìµœì¢… ê²°ê³¼ ì €ì¥
            if self.results:
                logger.info("ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ ì¤‘...")
                self.save_results_to_database()
                csv_file, json_file = self.save_results_to_files()
                
                # 5. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
                self.generate_comprehensive_report()
                
                # 6. ìµœì¢… í†µê³„
                success_rate = self.stats['successful'] / max(1, self.stats['total_analyzed']) * 100
                elapsed_time = (self.stats['end_time'] - self.stats['start_time']).total_seconds() / 60
                
                logger.info("ğŸ‰ ì „ì²´ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ!")
                logger.info(f"ğŸ“Š ìµœì¢… í†µê³„:")
                logger.info(f"   - ì´ ë¶„ì„ ì‹œë„: {self.stats['total_analyzed']:,}ê°œ")
                logger.info(f"   - ì„±ê³µ: {self.stats['successful']:,}ê°œ ({success_rate:.1f}%)")
                logger.info(f"   - ì‹¤íŒ¨: {self.stats['failed']:,}ê°œ")
                logger.info(f"   - ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ë¶„")
                logger.info(f"   - ë¶„ì„ ì†ë„: {self.stats['total_analyzed']/elapsed_time:.1f}ê°œ/ë¶„")
                
                if csv_file:
                    logger.info(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {csv_file}")
                
            else:
                logger.error("âŒ ë¶„ì„ ì„±ê³µí•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ì „ì²´ ì¢…ëª© ë°°ì¹˜ ë¶„ì„')
    parser.add_argument('--max-stocks', type=int, help='ìµœëŒ€ ë¶„ì„ ì¢…ëª© ìˆ˜')
    parser.add_argument('--save-interval', type=int, default=100, help='ì¤‘ê°„ ì €ì¥ ì£¼ê¸° (ê¸°ë³¸: 100ê°œ)')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (50ê°œ ì¢…ëª©)')
    parser.add_argument('--medium', action='store_true', help='ì¤‘ê°„ ê·œëª¨ (500ê°œ ì¢…ëª©)')
    
    args = parser.parse_args()
    
    print("ğŸ¯ ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ì „ì²´ ì¢…ëª© ë°°ì¹˜ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 80)
    
    analyzer = BuffettBatchAnalyzer()
    
    if args.test:
        print("ğŸ”§ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: 50ê°œ ì¢…ëª© ë¶„ì„")
        analyzer.run_batch_analysis(max_stocks=50, save_interval=25)
    elif args.medium:
        print("ğŸ“Š ì¤‘ê°„ ê·œëª¨: 500ê°œ ì¢…ëª© ë¶„ì„")
        analyzer.run_batch_analysis(max_stocks=500, save_interval=100)
    elif args.max_stocks:
        print(f"ğŸ”¢ ì œí•œ ëª¨ë“œ: {args.max_stocks}ê°œ ì¢…ëª© ë¶„ì„")
        analyzer.run_batch_analysis(max_stocks=args.max_stocks, save_interval=args.save_interval)
    else:
        print("âš ï¸ ì „ì²´ ì¢…ëª©ì„ ë¶„ì„í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì‹œê°„ì´ ë§¤ìš° ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        print("ğŸ’¡ ì¶”ì²œ: --test (50ê°œ), --medium (500ê°œ), --max-stocks N (Nê°œ)")
        response = input("ì „ì²´ ë¶„ì„ì„ ì›í•˜ë©´ 'yes' ì…ë ¥: ")
        
        if response.lower() == 'yes':
            print("ğŸš€ ì „ì²´ ì¢…ëª© ë¶„ì„ ì‹œì‘...")
            analyzer.run_batch_analysis(save_interval=args.save_interval)
        else:
            print("âŒ ë¶„ì„ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰: python buffett_batch_analyzer.py --test")

if __name__ == "__main__":
    main()
