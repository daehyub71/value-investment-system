#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì•„ëª¨ë ˆí¼ì‹œí”½ ë‰´ìŠ¤ ì¤‘ë³µ ë¬¸ì œ ë””ë²„ê¹…
"""

import sqlite3
import requests
import os
from datetime import datetime, timedelta
from dateutil import parser as date_parser
from dotenv import load_dotenv

load_dotenv()

def debug_amorepacific_news():
    """ì•„ëª¨ë ˆí¼ì‹œí”½ ë‰´ìŠ¤ ì¤‘ë³µ ë¬¸ì œ ë¶„ì„"""
    
    os.chdir('C:/data_analysis/value-investment-system/value-investment-system')
    news_db = 'data/databases/news_data.db'
    
    print("ğŸ” ì•„ëª¨ë ˆí¼ì‹œí”½ ë‰´ìŠ¤ ì¤‘ë³µ ë¬¸ì œ ë””ë²„ê¹…")
    print("=" * 60)
    
    # 1. í˜„ì¬ ì €ì¥ëœ ë‰´ìŠ¤ ë¶„ì„
    try:
        with sqlite3.connect(news_db) as conn:
            cursor = conn.cursor()
            
            print("ğŸ“Š í˜„ì¬ ì €ì¥ëœ ì•„ëª¨ë ˆí¼ì‹œí”½ ë‰´ìŠ¤ ë¶„ì„:")
            
            # ì´ ê°œìˆ˜
            cursor.execute("""
                SELECT COUNT(*) FROM news_articles 
                WHERE stock_code = '090430' OR company_name LIKE '%ì•„ëª¨ë ˆí¼ì‹œí”½%'
            """)
            total_count = cursor.fetchone()[0]
            print(f"   ì´ ë‰´ìŠ¤: {total_count}ê°œ")
            
            # ë‚ ì§œë³„ ë¶„í¬
            cursor.execute("""
                SELECT 
                    DATE(created_at) as date,
                    COUNT(*) as count
                FROM news_articles 
                WHERE stock_code = '090430' OR company_name LIKE '%ì•„ëª¨ë ˆí¼ì‹œí”½%'
                GROUP BY DATE(created_at)
                ORDER BY date DESC
                LIMIT 10
            """)
            
            date_dist = cursor.fetchall()
            print(f"   ìµœê·¼ ì €ì¥ì¼ë³„ ë¶„í¬:")
            for date, count in date_dist:
                print(f"     {date}: {count}ê°œ")
            
            # ìµœì‹  ë‰´ìŠ¤ í™•ì¸
            cursor.execute("""
                SELECT pubDate, title, originallink, created_at
                FROM news_articles 
                WHERE stock_code = '090430' OR company_name LIKE '%ì•„ëª¨ë ˆí¼ì‹œí”½%'
                ORDER BY created_at DESC
                LIMIT 5
            """)
            
            recent_news = cursor.fetchall()
            print(f"   ìµœê·¼ ì €ì¥ëœ ë‰´ìŠ¤:")
            for pub_date, title, link, created in recent_news:
                print(f"     ë°œí–‰: {pub_date}")
                print(f"     ì œëª©: {title[:50]}...")
                print(f"     ì €ì¥: {created}")
                print(f"     ë§í¬: {link[:50]}...")
                print()
            
            # URL ì¤‘ë³µ í™•ì¸
            cursor.execute("""
                SELECT originallink FROM news_articles 
                WHERE stock_code = '090430' 
                AND originallink IS NOT NULL 
                AND originallink != ''
                ORDER BY created_at DESC
                LIMIT 10
            """)
            
            existing_urls = [row[0] for row in cursor.fetchall()]
            print(f"   ê¸°ì¡´ URL ìƒ˜í”Œ (ìµœê·¼ 10ê°œ):")
            for i, url in enumerate(existing_urls, 1):
                print(f"     {i}. {url}")
                
    except Exception as e:
        print(f"âŒ ì €ì¥ëœ ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # 2. ë„¤ì´ë²„ ë‰´ìŠ¤ API ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ API ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸:")
    
    client_id = os.getenv('NAVER_CLIENT_ID')
    client_secret = os.getenv('NAVER_CLIENT_SECRET')
    
    if not client_id or not client_secret:
        print("âŒ ë„¤ì´ë²„ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        headers = {
            'X-Naver-Client-Id': client_id,
            'X-Naver-Client-Secret': client_secret
        }
        
        params = {
            'query': 'ì•„ëª¨ë ˆí¼ì‹œí”½',
            'display': 20,
            'start': 1,
            'sort': 'date'
        }
        
        response = requests.get(
            "https://openapi.naver.com/v1/search/news.json",
            headers=headers,
            params=params,
            timeout=30
        )
        response.raise_for_status()
        
        data = response.json()
        news_items = data.get('items', [])
        
        print(f"   API ì‘ë‹µ: {len(news_items)}ê°œ ë‰´ìŠ¤")
        
        if news_items:
            print(f"   ìµœì‹  ë‰´ìŠ¤ ë¶„ì„:")
            
            cutoff_date = datetime.now().date() - timedelta(days=30)
            recent_count = 0
            
            for i, item in enumerate(news_items[:10]):
                pub_date_str = item.get('pubDate', '')
                title = item.get('title', '').replace('<b>', '').replace('</b>', '')
                link = item.get('originallink', item.get('link', ''))
                
                try:
                    if pub_date_str:
                        pub_date = date_parser.parse(pub_date_str).date()
                        is_recent = pub_date >= cutoff_date
                        if is_recent:
                            recent_count += 1
                    else:
                        is_recent = "ë‚ ì§œì—†ìŒ"
                except:
                    is_recent = "íŒŒì‹±ì‹¤íŒ¨"
                
                print(f"     {i+1:2d}. {pub_date_str}")
                print(f"         ì œëª©: {title[:60]}...")
                print(f"         ë§í¬: {link[:60]}...")
                print(f"         ìµœê·¼: {is_recent}")
                print()
            
            print(f"   ìµœê·¼ 30ì¼ ë‰´ìŠ¤: {recent_count}ê°œ")
            
            # 3. ì¤‘ë³µ ì²´í¬ ì‹œë®¬ë ˆì´ì…˜
            print(f"\nğŸ” ì¤‘ë³µ ì²´í¬ ì‹œë®¬ë ˆì´ì…˜:")
            
            try:
                with sqlite3.connect(news_db) as conn:
                    existing_urls = set()
                    cursor = conn.execute("SELECT originallink FROM news_articles WHERE stock_code = '090430'")
                    existing_urls.update(row[0] for row in cursor.fetchall() if row[0])
                    
                    print(f"   ê¸°ì¡´ URL ìˆ˜: {len(existing_urls)}ê°œ")
                    
                    new_count = 0
                    duplicate_count = 0
                    
                    for item in news_items[:10]:
                        url = item.get('originallink', '')
                        if url:
                            if url in existing_urls:
                                duplicate_count += 1
                            else:
                                new_count += 1
                                print(f"   ì‹ ê·œ URL: {url[:60]}...")
                    
                    print(f"   ì‹ ê·œ: {new_count}ê°œ, ì¤‘ë³µ: {duplicate_count}ê°œ")
                    
                    if new_count == 0:
                        print("   âš ï¸ ëª¨ë“  ë‰´ìŠ¤ê°€ ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
                        print("   ğŸ’¡ ë” ë§ì€ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                    
            except Exception as e:
                print(f"   âŒ ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {e}")
        
    except Exception as e:
        print(f"âŒ API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def force_collect_latest_news():
    """ê°•ì œë¡œ ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œë„"""
    
    print(f"\nğŸš€ ê°•ì œ ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œë„")
    print("-" * 40)
    
    client_id = os.getenv('NAVER_CLIENT_ID')
    client_secret = os.getenv('NAVER_CLIENT_SECRET')
    news_db = 'data/databases/news_data.db'
    
    if not client_id or not client_secret:
        print("âŒ API í‚¤ ì—†ìŒ")
        return
    
    try:
        headers = {
            'X-Naver-Client-Id': client_id,
            'X-Naver-Client-Secret': client_secret
        }
        
        # ë” ë§ì€ í˜ì´ì§€ ìˆ˜ì§‘
        all_news = []
        
        for page in range(1, 6):  # 5í˜ì´ì§€ê¹Œì§€
            start_index = (page - 1) * 100 + 1
            
            params = {
                'query': 'ì•„ëª¨ë ˆí¼ì‹œí”½',
                'display': 100,
                'start': start_index,
                'sort': 'date'
            }
            
            response = requests.get(
                "https://openapi.naver.com/v1/search/news.json",
                headers=headers,
                params=params,
                timeout=30
            )
            response.raise_for_status()
            
            data = response.json()
            news_items = data.get('items', [])
            
            if not news_items:
                break
            
            all_news.extend(news_items)
            print(f"   í˜ì´ì§€ {page}: {len(news_items)}ê°œ ìˆ˜ì§‘")
        
        print(f"âœ… ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘")
        
        # ì¤‘ë³µ ì œê±° í›„ ì €ì¥
        with sqlite3.connect(news_db) as conn:
            existing_urls = set()
            cursor = conn.execute("SELECT originallink FROM news_articles WHERE stock_code = '090430'")
            existing_urls.update(row[0] for row in cursor.fetchall() if row[0])
            
            new_count = 0
            
            for item in all_news:
                url = item.get('originallink', '')
                if url and url not in existing_urls:
                    try:
                        title = item.get('title', '').replace('<b>', '').replace('</b>', '')
                        description = item.get('description', '').replace('<b>', '').replace('</b>', '')
                        
                        conn.execute('''
                            INSERT INTO news_articles 
                            (stock_code, title, description, originallink, link, pubDate, 
                             source, category, sentiment_score, sentiment_label, confidence_score, 
                             keywords, created_at, company_name)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            '090430', title, description, url, item.get('link', ''),
                            item.get('pubDate', ''), 'ë„¤ì´ë²„ë‰´ìŠ¤', 'ê¸ˆìœµ', 0.0, 'neutral', 0.5,
                            '', datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'ì•„ëª¨ë ˆí¼ì‹œí”½'
                        ))
                        
                        new_count += 1
                        existing_urls.add(url)
                        
                    except Exception as e:
                        continue
            
            conn.commit()
            
            print(f"âœ… {new_count}ê°œ ì‹ ê·œ ë‰´ìŠ¤ ì €ì¥")
            
            # ìµœì¢… í™•ì¸
            cursor = conn.execute("SELECT COUNT(*) FROM news_articles WHERE stock_code = '090430'")
            total = cursor.fetchone()[0]
            print(f"ğŸ“Š ì•„ëª¨ë ˆí¼ì‹œí”½ ì´ ë‰´ìŠ¤: {total}ê°œ")
        
    except Exception as e:
        print(f"âŒ ê°•ì œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    debug_amorepacific_news()
    
    print(f"\n" + "=" * 60)
    proceed = input("ê°•ì œë¡œ ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œë„í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
    
    if proceed == 'y':
        force_collect_latest_news()

if __name__ == "__main__":
    main()
