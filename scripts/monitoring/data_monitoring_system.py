#!/usr/bin/env python3
"""
ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ì‹œìŠ¤í…œ ë°ì´í„° ëª¨ë‹ˆí„°ë§ ë° ë°±ì—… ì‹œìŠ¤í…œ
scripts/monitoring/data_monitoring_system.py

- ì‹¤ì‹œê°„ ë°ì´í„° ìƒíƒœ ëª¨ë‹ˆí„°ë§
- ìë™ ë°±ì—… ë° ë³µêµ¬ ì‹œìŠ¤í…œ
- ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬
- ì´ë©”ì¼ ì•Œë¦¼ ì‹œìŠ¤í…œ
- ë°ì´í„° í’ˆì§ˆ ê²€ì¦
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
import sqlite3
import shutil
import json
import logging
import smtplib
import gzip
from typing import Dict, List, Optional, Tuple, Any
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
from email.mime.base import MimeBase
from email import encoders
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from config.database_config import get_db_connection, get_database_path
    from config.settings import get_database_info
except ImportError:
    print("âš ï¸ config ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    # ê¸°ë³¸ í•¨ìˆ˜ë“¤ì„ ì—¬ê¸°ì„œ ì •ì˜
    def get_db_connection(db_name):
        db_path = Path(f'data/databases/{db_name}_data.db')
        return sqlite3.connect(str(db_path))
    
    def get_database_path(db_name):
        return Path(f'data/databases/{db_name}_data.db')

# ë¡œê¹… ì„¤ì •
log_dir = project_root / 'logs'
log_dir.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / 'monitoring.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataMonitor:
    """ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ë°ì´í„° ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.databases = ['stock', 'dart', 'news', 'kis']
        self.critical_tables = {
            'stock': ['stock_prices', 'company_info', 'financial_ratios', 'technical_indicators', 'investment_scores'],
            'dart': ['corp_codes', 'financial_statements', 'disclosures', 'company_outlines'],
            'news': ['news_articles', 'sentiment_scores', 'market_sentiment'],
            'kis': ['realtime_quotes', 'account_balance', 'order_history', 'market_indicators']
        }
    
    def check_data_freshness(self) -> Dict[str, Dict]:
        """ë°ì´í„° ìµœì‹ ì„± ì²´í¬ - ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ íŠ¹í™”"""
        logger.info("ğŸ” ë°ì´í„° ìµœì‹ ì„± ì²´í¬ ì‹œì‘...")
        results = {}
        
        for db_name in self.databases:
            try:
                results[db_name] = self._check_database_freshness(db_name)
                logger.debug(f"{db_name} ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"{db_name} ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
                results[db_name] = {'error': str(e)}
        
        return results
    
    def _check_database_freshness(self, db_name: str) -> Dict:
        """ê°œë³„ ë°ì´í„°ë² ì´ìŠ¤ ìµœì‹ ì„± ì²´í¬"""
        try:
            with get_db_connection(db_name) as conn:
                if db_name == 'stock':
                    return self._check_stock_freshness(conn)
                elif db_name == 'news':
                    return self._check_news_freshness(conn)
                elif db_name == 'dart':
                    return self._check_dart_freshness(conn)
                elif db_name == 'kis':
                    return self._check_kis_freshness(conn)
                else:
                    return {'status': 'not_implemented'}
                    
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬ ì‹¤íŒ¨ ({db_name}): {e}")
            return {'error': str(e)}
    
    def _check_stock_freshness(self, conn: sqlite3.Connection) -> Dict:
        """ì£¼ê°€ ë°ì´í„° ìµœì‹ ì„± ì²´í¬ (ê¸°ìˆ ë¶„ì„ 30% + ê¸°ë³¸ë¶„ì„ 45%)"""
        try:
            # 1. ì£¼ê°€ ë°ì´í„° ìµœì‹ ì„± (ê¸°ìˆ ë¶„ì„ 30% ë¹„ì¤‘)
            stock_query = """
                SELECT 
                    MAX(date) as latest_date, 
                    COUNT(DISTINCT stock_code) as stock_count,
                    COUNT(*) as total_records
                FROM stock_prices
                WHERE date >= date('now', '-7 days')
            """
            stock_result = pd.read_sql(stock_query, conn).iloc[0]
            
            # 2. ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ìµœì‹ ì„± (ê¸°ë³¸ë¶„ì„ 45% ë¹„ì¤‘)
            buffett_query = """
                SELECT 
                    COUNT(*) as scored_companies,
                    AVG(total_buffett_score) as avg_score,
                    MAX(updated_at) as latest_update
                FROM financial_ratios
                WHERE total_buffett_score IS NOT NULL
            """
            
            try:
                buffett_result = pd.read_sql(buffett_query, conn).iloc[0]
            except:
                buffett_result = {'scored_companies': 0, 'avg_score': 0, 'latest_update': None}
            
            # 3. ê¸°ìˆ ì  ì§€í‘œ ìµœì‹ ì„±
            technical_query = """
                SELECT 
                    MAX(date) as latest_tech_date,
                    COUNT(DISTINCT stock_code) as tech_stock_count,
                    AVG(technical_score) as avg_tech_score
                FROM technical_indicators
                WHERE date >= date('now', '-7 days')
            """
            
            try:
                tech_result = pd.read_sql(technical_query, conn).iloc[0]
            except:
                tech_result = {'latest_tech_date': None, 'tech_stock_count': 0, 'avg_tech_score': 0}
            
            # ì˜ì—…ì¼ ê³„ì‚°
            today = datetime.now()
            if today.weekday() >= 5:  # ì£¼ë§
                expected_date = today - timedelta(days=today.weekday()-4)
            else:
                expected_date = today - timedelta(days=1) if today.hour >= 18 else today - timedelta(days=2)
            
            latest_date = stock_result['latest_date']
            is_fresh = latest_date == expected_date.strftime('%Y-%m-%d')
            
            return {
                'type': 'stock_analysis',
                'latest_date': latest_date,
                'expected_date': expected_date.strftime('%Y-%m-%d'),
                'stock_count': stock_result['stock_count'],
                'total_records': stock_result['total_records'],
                'is_fresh': is_fresh,
                
                # ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ì •ë³´
                'buffett_scorecard': {
                    'scored_companies': buffett_result['scored_companies'],
                    'avg_score': round(buffett_result['avg_score'] or 0, 2),
                    'latest_update': buffett_result['latest_update']
                },
                
                # ê¸°ìˆ ì  ë¶„ì„ ì •ë³´
                'technical_analysis': {
                    'latest_date': tech_result['latest_tech_date'],
                    'stock_count': tech_result['tech_stock_count'],
                    'avg_score': round(tech_result['avg_tech_score'] or 0, 2)
                },
                
                'health_score': self._calculate_stock_health_score(stock_result, buffett_result, tech_result, is_fresh)
            }
            
        except Exception as e:
            logger.error(f"ì£¼ê°€ ë°ì´í„° ì²´í¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _check_news_freshness(self, conn: sqlite3.Connection) -> Dict:
        """ë‰´ìŠ¤ ë°ì´í„° ìµœì‹ ì„± ì²´í¬ (ê°ì •ë¶„ì„ 25% ë¹„ì¤‘)"""
        try:
            # ë‰´ìŠ¤ ë°ì´í„° ìµœì‹ ì„±
            news_query = """
                SELECT 
                    DATE(MAX(created_at)) as latest_date, 
                    COUNT(*) as news_count,
                    COUNT(DISTINCT stock_code) as covered_stocks,
                    AVG(sentiment_score) as avg_sentiment
                FROM news_articles
                WHERE created_at >= datetime('now', '-1 day')
            """
            news_result = pd.read_sql(news_query, conn).iloc[0]
            
            # ê°ì •ë¶„ì„ ì ìˆ˜ ìµœì‹ ì„±
            sentiment_query = """
                SELECT 
                    COUNT(*) as analyzed_stocks,
                    AVG(sentiment_final_score) as avg_final_score,
                    MAX(updated_at) as latest_analysis
                FROM sentiment_scores
                WHERE date >= date('now', '-1 day')
            """
            
            try:
                sentiment_result = pd.read_sql(sentiment_query, conn).iloc[0]
            except:
                sentiment_result = {'analyzed_stocks': 0, 'avg_final_score': 0, 'latest_analysis': None}
            
            return {
                'type': 'sentiment_analysis',
                'latest_date': news_result['latest_date'],
                'news_count': news_result['news_count'],
                'covered_stocks': news_result['covered_stocks'],
                'avg_sentiment': round(news_result['avg_sentiment'] or 0, 3),
                'is_fresh': news_result['news_count'] > 0,
                
                'sentiment_analysis': {
                    'analyzed_stocks': sentiment_result['analyzed_stocks'],
                    'avg_final_score': round(sentiment_result['avg_final_score'] or 0, 2),
                    'latest_analysis': sentiment_result['latest_analysis']
                }
            }
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ì²´í¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _check_dart_freshness(self, conn: sqlite3.Connection) -> Dict:
        """DART ë°ì´í„° ìµœì‹ ì„± ì²´í¬ (ê¸°ë³¸ë¶„ì„ 45% ë¹„ì¤‘ ì§€ì›)"""
        try:
            disclosure_query = """
                SELECT 
                    DATE(MAX(created_at)) as latest_date, 
                    COUNT(*) as disclosure_count,
                    COUNT(DISTINCT corp_code) as corp_count
                FROM disclosures
                WHERE created_at >= datetime('now', '-7 days')
            """
            disclosure_result = pd.read_sql(disclosure_query, conn).iloc[0]
            
            financial_query = """
                SELECT 
                    COUNT(DISTINCT corp_code) as financial_corps,
                    MAX(created_at) as latest_financial
                FROM financial_statements
                WHERE created_at >= datetime('now', '-30 days')
            """
            
            try:
                financial_result = pd.read_sql(financial_query, conn).iloc[0]
            except:
                financial_result = {'financial_corps': 0, 'latest_financial': None}
            
            return {
                'type': 'fundamental_data',
                'latest_date': disclosure_result['latest_date'],
                'disclosure_count': disclosure_result['disclosure_count'],
                'corp_count': disclosure_result['corp_count'],
                'is_fresh': disclosure_result['disclosure_count'] > 0,
                
                'financial_data': {
                    'corps_with_data': financial_result['financial_corps'],
                    'latest_update': financial_result['latest_financial']
                }
            }
            
        except Exception as e:
            logger.error(f"DART ë°ì´í„° ì²´í¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _check_kis_freshness(self, conn: sqlite3.Connection) -> Dict:
        """KIS ë°ì´í„° ìµœì‹ ì„± ì²´í¬"""
        try:
            kis_query = """
                SELECT 
                    MAX(timestamp) as latest_timestamp,
                    COUNT(DISTINCT stock_code) as stock_count,
                    COUNT(*) as quote_count
                FROM realtime_quotes
                WHERE timestamp >= datetime('now', '-1 hour')
            """
            
            try:
                kis_result = pd.read_sql(kis_query, conn).iloc[0]
                return {
                    'type': 'realtime_data',
                    'latest_timestamp': kis_result['latest_timestamp'],
                    'stock_count': kis_result['stock_count'],
                    'quote_count': kis_result['quote_count'],
                    'is_fresh': kis_result['quote_count'] > 0
                }
            except:
                return {
                    'type': 'realtime_data',
                    'latest_timestamp': None,
                    'stock_count': 0,
                    'quote_count': 0,
                    'is_fresh': False
                }
                
        except Exception as e:
            logger.error(f"KIS ë°ì´í„° ì²´í¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _calculate_stock_health_score(self, stock_result, buffett_result, tech_result, is_fresh) -> int:
        """ì£¼ì‹ ë°ì´í„° ì¢…í•© ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚° (0-100)"""
        score = 0
        
        # ë°ì´í„° ìµœì‹ ì„± (30ì )
        if is_fresh:
            score += 30
        
        # ë°ì´í„° ì™„ì„±ë„ (40ì )
        if stock_result['stock_count'] > 2000:  # ìµœì†Œ ì¢…ëª© ìˆ˜
            score += 20
        if buffett_result['scored_companies'] > 1000:  # ìŠ¤ì½”ì–´ì¹´ë“œ ì ìš© ì¢…ëª©
            score += 20
        
        # ë°ì´í„° í’ˆì§ˆ (30ì )
        if buffett_result['avg_score'] > 0:  # í‰ê·  ìŠ¤ì½”ì–´ ì¡´ì¬
            score += 15
        if tech_result['avg_tech_score'] > 0:  # ê¸°ìˆ ì  ë¶„ì„ ì ìˆ˜ ì¡´ì¬
            score += 15
        
        return min(score, 100)
    
    def check_data_quality(self) -> Dict[str, Dict]:
        """ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ë°ì´í„° í’ˆì§ˆ ì²´í¬"""
        logger.info("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì²´í¬ ì‹œì‘...")
        results = {}
        
        # ì£¼ê°€ ë°ì´í„° í’ˆì§ˆ ì²´í¬
        results['stock_quality'] = self._check_stock_data_quality()
        
        # ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ í’ˆì§ˆ ì²´í¬
        results['buffett_quality'] = self._check_buffett_scorecard_quality()
        
        # ì¤‘ë³µ ë°ì´í„° ì²´í¬
        results['duplicates'] = self._check_duplicates()
        
        # ëˆ„ë½ ë°ì´í„° ì²´í¬
        results['missing_data'] = self._check_missing_data()
        
        return results
    
    def _check_stock_data_quality(self) -> Dict:
        """ì£¼ê°€ ë°ì´í„° í’ˆì§ˆ ì²´í¬"""
        try:
            with get_db_connection('stock') as conn:
                # ë¹„ì •ìƒì ì¸ ê°€ê²© ë°ì´í„° ì²´í¬
                invalid_query = """
                    SELECT COUNT(*) as invalid_count
                    FROM stock_prices
                    WHERE open_price <= 0 OR high_price <= 0 OR low_price <= 0 OR close_price <= 0
                       OR high_price < low_price
                       OR open_price NOT BETWEEN low_price AND high_price
                       OR close_price NOT BETWEEN low_price AND high_price
                """
                invalid_count = pd.read_sql(invalid_query, conn).iloc[0]['invalid_count']
                
                # ì „ì²´ ë ˆì½”ë“œ ìˆ˜
                total_query = "SELECT COUNT(*) as total FROM stock_prices"
                total_count = pd.read_sql(total_query, conn).iloc[0]['total']
                
                # ìµœê·¼ 7ì¼ ë°ì´í„° ì™„ì„±ë„
                recent_query = """
                    SELECT 
                        COUNT(DISTINCT stock_code) as recent_stocks,
                        COUNT(DISTINCT date) as recent_dates
                    FROM stock_prices 
                    WHERE date >= date('now', '-7 days')
                """
                recent_result = pd.read_sql(recent_query, conn).iloc[0]
                
                quality_score = (total_count - invalid_count) / total_count * 100 if total_count > 0 else 0
                
                return {
                    'total_records': total_count,
                    'invalid_records': invalid_count,
                    'quality_score': round(quality_score, 2),
                    'recent_stocks': recent_result['recent_stocks'],
                    'recent_dates': recent_result['recent_dates'],
                    'status': 'excellent' if quality_score >= 99 else 'good' if quality_score >= 95 else 'poor'
                }
                
        except Exception as e:
            logger.error(f"ì£¼ê°€ ë°ì´í„° í’ˆì§ˆ ì²´í¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _check_buffett_scorecard_quality(self) -> Dict:
        """ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ í’ˆì§ˆ ì²´í¬"""
        try:
            with get_db_connection('stock') as conn:
                scorecard_query = """
                    SELECT 
                        COUNT(*) as total_companies,
                        COUNT(CASE WHEN total_buffett_score IS NOT NULL THEN 1 END) as scored_companies,
                        AVG(total_buffett_score) as avg_total_score,
                        AVG(profitability_score) as avg_profitability,
                        AVG(growth_score) as avg_growth,
                        AVG(stability_score) as avg_stability,
                        AVG(efficiency_score) as avg_efficiency,
                        AVG(valuation_score) as avg_valuation,
                        MIN(total_buffett_score) as min_score,
                        MAX(total_buffett_score) as max_score
                    FROM financial_ratios
                    WHERE quarter IS NULL  -- ì—°ê°„ ë°ì´í„°ë§Œ
                """
                
                result = pd.read_sql(scorecard_query, conn).iloc[0]
                
                # ìŠ¤ì½”ì–´ì¹´ë“œ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
                coverage = result['scored_companies'] / result['total_companies'] * 100 if result['total_companies'] > 0 else 0
                
                # ì ìˆ˜ ë¶„í¬ ì²´í¬
                distribution_query = """
                    SELECT 
                        COUNT(CASE WHEN total_buffett_score >= 90 THEN 1 END) as excellent,
                        COUNT(CASE WHEN total_buffett_score >= 80 AND total_buffett_score < 90 THEN 1 END) as very_good,
                        COUNT(CASE WHEN total_buffett_score >= 70 AND total_buffett_score < 80 THEN 1 END) as good,
                        COUNT(CASE WHEN total_buffett_score >= 60 AND total_buffett_score < 70 THEN 1 END) as fair,
                        COUNT(CASE WHEN total_buffett_score < 60 THEN 1 END) as poor
                    FROM financial_ratios
                    WHERE total_buffett_score IS NOT NULL AND quarter IS NULL
                """
                
                distribution = pd.read_sql(distribution_query, conn).iloc[0]
                
                return {
                    'total_companies': result['total_companies'],
                    'scored_companies': result['scored_companies'],
                    'coverage_percentage': round(coverage, 2),
                    'avg_scores': {
                        'total': round(result['avg_total_score'] or 0, 2),
                        'profitability': round(result['avg_profitability'] or 0, 2),
                        'growth': round(result['avg_growth'] or 0, 2),
                        'stability': round(result['avg_stability'] or 0, 2),
                        'efficiency': round(result['avg_efficiency'] or 0, 2),
                        'valuation': round(result['avg_valuation'] or 0, 2)
                    },
                    'score_range': {
                        'min': result['min_score'],
                        'max': result['max_score']
                    },
                    'grade_distribution': {
                        'excellent': distribution['excellent'],
                        'very_good': distribution['very_good'],
                        'good': distribution['good'],
                        'fair': distribution['fair'],
                        'poor': distribution['poor']
                    },
                    'status': 'excellent' if coverage >= 90 else 'good' if coverage >= 70 else 'poor'
                }
                
        except Exception as e:
            logger.error(f"ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ í’ˆì§ˆ ì²´í¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _check_duplicates(self) -> Dict:
        """ì¤‘ë³µ ë°ì´í„° ì²´í¬"""
        results = {}
        
        try:
            # ì£¼ê°€ ë°ì´í„° ì¤‘ë³µ ì²´í¬
            with get_db_connection('stock') as conn:
                stock_dup_query = """
                    SELECT stock_code, date, COUNT(*) as dup_count
                    FROM stock_prices
                    GROUP BY stock_code, date
                    HAVING COUNT(*) > 1
                """
                stock_duplicates = pd.read_sql(stock_dup_query, conn)
                results['stock_duplicates'] = len(stock_duplicates)
            
            # ë‰´ìŠ¤ ë°ì´í„° ì¤‘ë³µ ì²´í¬
            with get_db_connection('news') as conn:
                news_dup_query = """
                    SELECT title, pubDate, COUNT(*) as dup_count
                    FROM news_articles
                    GROUP BY title, pubDate
                    HAVING COUNT(*) > 1
                """
                news_duplicates = pd.read_sql(news_dup_query, conn)
                results['news_duplicates'] = len(news_duplicates)
                
        except Exception as e:
            logger.error(f"ì¤‘ë³µ ë°ì´í„° ì²´í¬ ì‹¤íŒ¨: {e}")
            results['error'] = str(e)
        
        return results
    
    def _check_missing_data(self) -> Dict:
        """ëˆ„ë½ ë°ì´í„° ì²´í¬"""
        try:
            # ìµœê·¼ 5ì¼ê°„ ì˜ì—…ì¼ ì¤‘ ëˆ„ë½ëœ ë‚ ì§œ ì²´í¬
            with get_db_connection('stock') as conn:
                # ì˜ì—…ì¼ ìƒì„± (ì£¼ë§ ì œì™¸)
                end_date = datetime.now()
                start_date = end_date - timedelta(days=10)
                date_range = pd.date_range(start=start_date, end=end_date, freq='B')
                
                missing_dates = []
                for date in date_range:
                    date_str = date.strftime('%Y-%m-%d')
                    count_query = f"SELECT COUNT(DISTINCT stock_code) as count FROM stock_prices WHERE date = '{date_str}'"
                    count_result = pd.read_sql(count_query, conn).iloc[0]['count']
                    
                    if count_result == 0:
                        missing_dates.append(date_str)
                
                return {
                    'missing_dates': missing_dates,
                    'missing_count': len(missing_dates),
                    'status': 'good' if len(missing_dates) == 0 else 'warning' if len(missing_dates) <= 2 else 'critical'
                }
                
        except Exception as e:
            logger.error(f"ëˆ„ë½ ë°ì´í„° ì²´í¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def generate_health_report(self) -> Dict:
        """ì‹œìŠ¤í…œ ì¢…í•© í—¬ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            logger.info("ğŸ¥ ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬ ì‹œì‘...")
            
            report = {
                'timestamp': datetime.now().isoformat(),
                'system_name': 'Warren Buffett Investment System',
                'version': '1.0.0',
                'data_freshness': self.check_data_freshness(),
                'data_quality': self.check_data_quality(),
                'database_sizes': self._get_database_sizes(),
                'system_status': 'healthy',
                'issues': [],
                'recommendations': []
            }
            
            # ì „ì²´ ìƒíƒœ í‰ê°€
            issues = []
            recommendations = []
            
            # ë°ì´í„° ìµœì‹ ì„± ë¬¸ì œ ì²´í¬
            for db_name, freshness in report['data_freshness'].items():
                if 'error' in freshness:
                    issues.append(f"âŒ {db_name} ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {freshness['error']}")
                elif not freshness.get('is_fresh', False):
                    issues.append(f"âš ï¸ {db_name} ë°ì´í„°ê°€ ìµœì‹ ì´ ì•„ë‹˜")
                    recommendations.append(f"ğŸ“… {db_name} ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤í–‰ í•„ìš”")
            
            # ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ í’ˆì§ˆ ì²´í¬
            buffett_quality = report['data_quality'].get('buffett_quality', {})
            if buffett_quality.get('coverage_percentage', 0) < 70:
                issues.append(f"ğŸ“Š ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ ì»¤ë²„ë¦¬ì§€ ë¶€ì¡± ({buffett_quality.get('coverage_percentage', 0)}%)")
                recommendations.append("ğŸ”„ ì¬ë¬´ë°ì´í„° ìˆ˜ì§‘ ë° ìŠ¤ì½”ì–´ì¹´ë“œ ê³„ì‚° ì¬ì‹¤í–‰ í•„ìš”")
            
            # ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ ì²´í¬
            stock_quality = report['data_quality'].get('stock_quality', {})
            if stock_quality.get('quality_score', 100) < 95:
                issues.append(f"ğŸ“ˆ ì£¼ê°€ ë°ì´í„° í’ˆì§ˆ ì €í•˜ ({stock_quality.get('quality_score', 0)}%)")
                recommendations.append("ğŸ§¹ ë°ì´í„° ì •ë¦¬ ë° ê²€ì¦ í•„ìš”")
            
            # ì¤‘ë³µ ë°ì´í„° ë¬¸ì œ ì²´í¬
            duplicates = report['data_quality'].get('duplicates', {})
            if duplicates.get('stock_duplicates', 0) > 0:
                issues.append(f"ğŸ”„ ì£¼ê°€ ë°ì´í„° ì¤‘ë³µ {duplicates['stock_duplicates']}ê±´")
                recommendations.append("ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì œê±° í•„ìš”")
            
            # ëˆ„ë½ ë°ì´í„° ë¬¸ì œ ì²´í¬
            missing_data = report['data_quality'].get('missing_data', {})
            if missing_data.get('missing_count', 0) > 0:
                issues.append(f"ğŸ“… ëˆ„ë½ëœ ë‚ ì§œ {missing_data['missing_count']}ê°œ")
                recommendations.append("ğŸ”„ ëˆ„ë½ ë°ì´í„° ë³´ì™„ ì‹¤í–‰ í•„ìš”")
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ê²°ì •
            if len(issues) == 0:
                report['system_status'] = 'excellent'
            elif len(issues) <= 2:
                report['system_status'] = 'good'
            elif len(issues) <= 5:
                report['system_status'] = 'warning'
            else:
                report['system_status'] = 'critical'
            
            report['issues'] = issues
            report['recommendations'] = recommendations
            report['summary'] = self._generate_summary(report)
            
            logger.info(f"âœ… ì‹œìŠ¤í…œ ìƒíƒœ: {report['system_status']} ({len(issues)}ê°œ ì´ìŠˆ)")
            return report
            
        except Exception as e:
            logger.error(f"í—¬ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'system_name': 'Warren Buffett Investment System',
                'system_status': 'error',
                'error': str(e)
            }
    
    def _generate_summary(self, report: Dict) -> Dict:
        """ë¦¬í¬íŠ¸ ìš”ì•½ ìƒì„±"""
        try:
            stock_data = report['data_freshness'].get('stock', {})
            buffett_data = report['data_quality'].get('buffett_quality', {})
            
            return {
                'total_companies': buffett_data.get('total_companies', 0),
                'buffett_scored': buffett_data.get('scored_companies', 0),
                'avg_buffett_score': buffett_data.get('avg_scores', {}).get('total', 0),
                'latest_stock_date': stock_data.get('latest_date', 'N/A'),
                'stock_coverage': stock_data.get('stock_count', 0),
                'health_score': stock_data.get('health_score', 0),
                'issue_count': len(report.get('issues', [])),
                'recommendation_count': len(report.get('recommendations', []))
            }
        except Exception as e:
            logger.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    def _get_database_sizes(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ì •ë³´"""
        sizes = {}
        
        for db_name in self.databases:
            try:
                db_path = get_database_path(db_name)
                if db_path.exists():
                    size_mb = db_path.stat().st_size / (1024 * 1024)
                    sizes[db_name] = round(size_mb, 2)
                else:
                    sizes[db_name] = 0
            except Exception as e:
                sizes[db_name] = f"error: {e}"
        
        return sizes

class DataBackupManager:
    """ë°ì´í„° ë°±ì—… ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.backup_dir = project_root / 'backups'
        self.backup_dir.mkdir(exist_ok=True)
        self.databases = ['stock', 'dart', 'news', 'kis']
    
    def create_backup(self, backup_type: str = 'daily') -> Dict[str, str]:
        """ë°±ì—… ìƒì„±"""
        try:
            logger.info(f"ğŸ’¾ {backup_type} ë°±ì—… ìƒì„± ì‹œì‘...")
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_results = {}
            
            for db_name in self.databases:
                try:
                    source_path = get_database_path(db_name)
                    
                    if source_path.exists():
                        backup_filename = f"{db_name}_{backup_type}_{timestamp}.db"
                        backup_path = self.backup_dir / backup_filename
                        
                        # ë°±ì—… ì‹¤í–‰
                        shutil.copy2(source_path, backup_path)
                        
                        # ì£¼ê°„ ë°±ì—…ì€ ì••ì¶•
                        if backup_type == 'weekly':
                            with open(backup_path, 'rb') as f_in:
                                with gzip.open(f"{backup_path}.gz", 'wb') as f_out:
                                    shutil.copyfileobj(f_in, f_out)
                            backup_path.unlink()  # ì›ë³¸ ì‚­ì œ
                            backup_path = f"{backup_path}.gz"
                        
                        backup_results[db_name] = str(backup_path)
                        logger.info(f"âœ… ë°±ì—… ì™„ë£Œ: {db_name} -> {backup_path.name}")
                    else:
                        backup_results[db_name] = "database_not_found"
                        logger.warning(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì—†ìŒ: {db_name}")
                        
                except Exception as e:
                    backup_results[db_name] = f"error: {str(e)}"
                    logger.error(f"âŒ ë°±ì—… ì‹¤íŒ¨ ({db_name}): {e}")
            
            logger.info(f"ğŸ“¦ ë°±ì—… ì‘ì—… ì™„ë£Œ: {len([r for r in backup_results.values() if not r.startswith('error')])}/{len(self.databases)}ê°œ ì„±ê³µ")
            return backup_results
            
        except Exception as e:
            logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def cleanup_old_backups(self, keep_days: int = 30) -> int:
        """ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬"""
        try:
            logger.info(f"ğŸ§¹ {keep_days}ì¼ ì´ìƒëœ ë°±ì—… íŒŒì¼ ì •ë¦¬...")
            cutoff_date = datetime.now() - timedelta(days=keep_days)
            deleted_count = 0
            
            for backup_file in self.backup_dir.glob("*.db*"):
                if backup_file.stat().st_mtime < cutoff_date.timestamp():
                    backup_file.unlink()
                    deleted_count += 1
                    logger.debug(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {backup_file.name}")
            
            logger.info(f"âœ… {deleted_count}ê°œ ë°±ì—… íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            return deleted_count
            
        except Exception as e:
            logger.error(f"ë°±ì—… ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0
    
    def restore_backup(self, backup_file: str, target_db: str) -> bool:
        """ë°±ì—… ë³µì›"""
        try:
            logger.info(f"ğŸ”„ ë°±ì—… ë³µì›: {backup_file} -> {target_db}")
            backup_path = Path(backup_file)
            target_path = get_database_path(target_db)
            
            if not backup_path.exists():
                logger.error(f"âŒ ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {backup_path}")
                return False
            
            # í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
            current_backup = f"{target_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            if target_path.exists():
                shutil.copy2(target_path, current_backup)
                logger.info(f"ğŸ’¾ ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…: {current_backup}")
            
            # ë°±ì—… ë³µì›
            if backup_path.suffix == '.gz':
                with gzip.open(backup_path, 'rb') as f_in:
                    with open(target_path, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
            else:
                shutil.copy2(backup_path, target_path)
            
            logger.info(f"âœ… ë°±ì—… ë³µì› ì™„ë£Œ: {backup_file} -> {target_path}")
            return True
            
        except Exception as e:
            logger.error(f"ë°±ì—… ë³µì› ì‹¤íŒ¨: {e}")
            return False
    
    def list_backups(self) -> List[Dict]:
        """ë°±ì—… íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        backups = []
        
        try:
            for backup_file in sorted(self.backup_dir.glob("*.db*"), key=lambda x: x.stat().st_mtime, reverse=True):
                stat = backup_file.stat()
                backups.append({
                    'filename': backup_file.name,
                    'path': str(backup_file),
                    'size_mb': round(stat.st_size / (1024 * 1024), 2),
                    'created': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                    'database': backup_file.name.split('_')[0],
                    'type': backup_file.name.split('_')[1] if '_' in backup_file.name else 'unknown'
                })
        except Exception as e:
            logger.error(f"ë°±ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return backups

class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì´ë©”ì¼ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        self.smtp_server = os.getenv('SMTP_SERVER', 'smtp.gmail.com')
        self.smtp_port = int(os.getenv('SMTP_PORT', '587'))
        self.email_user = os.getenv('EMAIL_USER')
        self.email_password = os.getenv('EMAIL_PASSWORD')
        self.alert_recipients = [email.strip() for email in os.getenv('ALERT_RECIPIENTS', '').split(',') if email.strip()]
        
        # ì´ë©”ì¼ ì„¤ì • ê²€ì¦
        self.email_enabled = bool(self.email_user and self.email_password and self.alert_recipients)
        
        if not self.email_enabled:
            logger.warning("âš ï¸ ì´ë©”ì¼ ì„¤ì •ì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. ì•Œë¦¼ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    
    def send_health_alert(self, health_report: Dict):
        """í—¬ìŠ¤ ì²´í¬ ì•Œë¦¼ ì „ì†¡"""
        try:
            if health_report['system_status'] in ['warning', 'critical', 'error']:
                status_icons = {
                    'warning': 'âš ï¸',
                    'critical': 'ğŸš¨',
                    'error': 'âŒ'
                }
                
                icon = status_icons.get(health_report['system_status'], 'âš ï¸')
                subject = f"{icon} ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ì•Œë¦¼: {health_report['system_status'].upper()}"
                
                body = self._format_health_report_email(health_report)
                
                if self._send_email(subject, body):
                    logger.info(f"ğŸ“§ í—¬ìŠ¤ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: {health_report['system_status']}")
                else:
                    logger.error("ğŸ“§ í—¬ìŠ¤ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
                    
        except Exception as e:
            logger.error(f"í—¬ìŠ¤ ì•Œë¦¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def send_backup_notification(self, backup_results: Dict):
        """ë°±ì—… ì™„ë£Œ ì•Œë¦¼"""
        try:
            if backup_results and 'error' not in backup_results:
                successful_backups = [db for db, result in backup_results.items() if not result.startswith('error')]
                failed_backups = [db for db, result in backup_results.items() if result.startswith('error')]
                
                if successful_backups:
                    subject = f"âœ… ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ë°±ì—… ì™„ë£Œ ({len(successful_backups)}/{len(backup_results)})"
                    
                    body = f"""
ğŸ¯ ì›ŒëŸ° ë²„í• íˆ¬ì ì‹œìŠ¤í…œ ë°±ì—… ë¦¬í¬íŠ¸

ğŸ• ë°±ì—… ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“Š ì„±ê³µ/ì „ì²´: {len(successful_backups)}/{len(backup_results)}

âœ… ì„±ê³µí•œ ë°±ì—…:
"""
                    
                    for db_name in successful_backups:
                        backup_path = backup_results[db_name]
                        body += f"  â€¢ {db_name}: {Path(backup_path).name}\n"
                    
                    if failed_backups:
                        body += f"\nâŒ ì‹¤íŒ¨í•œ ë°±ì—…:\n"
                        for db_name in failed_backups:
                            body += f"  â€¢ {db_name}: {backup_results[db_name]}\n"
                    
                    body += f"\nğŸ’¾ ë°±ì—… ìœ„ì¹˜: {Path('backups').absolute()}"
                    
                    if self._send_email(subject, body):
                        logger.info("ğŸ“§ ë°±ì—… ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
            else:
                # ë°±ì—… ì‹¤íŒ¨ ì•Œë¦¼
                subject = "âŒ ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ë°±ì—… ì‹¤íŒ¨"
                body = f"""
ë°±ì—… ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.

ğŸ• ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
âŒ ì˜¤ë¥˜: {backup_results.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}

ğŸ“ ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.
"""
                self._send_email(subject, body)
                
        except Exception as e:
            logger.error(f"ë°±ì—… ì•Œë¦¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def send_daily_summary(self, health_report: Dict):
        """ì¼ì¼ ìš”ì•½ ë³´ê³ ì„œ ì „ì†¡"""
        try:
            subject = f"ğŸ“Š ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ì¼ì¼ ë¦¬í¬íŠ¸ - {datetime.now().strftime('%Y-%m-%d')}"
            body = self._format_daily_summary_email(health_report)
            
            if self._send_email(subject, body):
                logger.info("ğŸ“§ ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _format_health_report_email(self, health_report: Dict) -> str:
        """í—¬ìŠ¤ ë¦¬í¬íŠ¸ ì´ë©”ì¼ í¬ë§·"""
        try:
            summary = health_report.get('summary', {})
            
            body = f"""
ğŸ¯ ì›ŒëŸ° ë²„í• íˆ¬ì ì‹œìŠ¤í…œ í—¬ìŠ¤ ë¦¬í¬íŠ¸

ğŸ• ì²´í¬ ì‹œê°„: {health_report['timestamp']}
ğŸš¨ ì‹œìŠ¤í…œ ìƒíƒœ: {health_report['system_status'].upper()}
ğŸ“Š ì‹œìŠ¤í…œ ê±´ê°•ë„: {summary.get('health_score', 0)}/100

ğŸ“ˆ ì‹œìŠ¤í…œ ìš”ì•½:
â€¢ ì´ ìƒì¥ê¸°ì—…: {summary.get('total_companies', 0):,}ê°œ
â€¢ ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ ì ìš©: {summary.get('buffett_scored', 0):,}ê°œ
â€¢ í‰ê·  ë²„í• ì ìˆ˜: {summary.get('avg_buffett_score', 0):.1f}/110ì 
â€¢ ìµœì‹  ì£¼ê°€ ë‚ ì§œ: {summary.get('latest_stock_date', 'N/A')}
â€¢ ì£¼ê°€ ë°ì´í„° ì¢…ëª© ìˆ˜: {summary.get('stock_coverage', 0):,}ê°œ

"""
            
            if health_report.get('issues'):
                body += "ğŸš¨ ë°œê²¬ëœ ë¬¸ì œì :\n"
                for issue in health_report['issues']:
                    body += f"  {issue}\n"
                body += "\n"
            
            if health_report.get('recommendations'):
                body += "ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­:\n"
                for rec in health_report['recommendations']:
                    body += f"  {rec}\n"
                body += "\n"
            
            # ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ì •ë³´
            if 'database_sizes' in health_report:
                body += "ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°:\n"
                for db_name, size in health_report['database_sizes'].items():
                    if isinstance(size, (int, float)):
                        body += f"  â€¢ {db_name}: {size:.1f} MB\n"
                    else:
                        body += f"  â€¢ {db_name}: {size}\n"
                body += "\n"
            
            body += "ğŸ“ ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            
            return body
            
        except Exception as e:
            logger.error(f"í—¬ìŠ¤ ë¦¬í¬íŠ¸ ì´ë©”ì¼ í¬ë§· ì‹¤íŒ¨: {e}")
            return f"í—¬ìŠ¤ ë¦¬í¬íŠ¸ í¬ë§· ì˜¤ë¥˜: {str(e)}"
    
    def _format_daily_summary_email(self, health_report: Dict) -> str:
        """ì¼ì¼ ìš”ì•½ ì´ë©”ì¼ í¬ë§·"""
        try:
            summary = health_report.get('summary', {})
            
            return f"""
ğŸ“Š ì›ŒëŸ° ë²„í• íˆ¬ì ì‹œìŠ¤í…œ ì¼ì¼ ìš”ì•½

ğŸ“… ë‚ ì§œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}
ğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ: {health_report['system_status'].upper()}

ğŸ¯ ì˜¤ëŠ˜ì˜ ì£¼ìš” ì§€í‘œ:
â€¢ ğŸ“ˆ ë¶„ì„ëœ ì¢…ëª©: {summary.get('stock_coverage', 0):,}ê°œ
â€¢ ğŸ† ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ í‰ê· : {summary.get('avg_buffett_score', 0):.1f}/110ì 
â€¢ ğŸ“Š ì‹œìŠ¤í…œ ê±´ê°•ë„: {summary.get('health_score', 0)}/100ì 
â€¢ ğŸ” ë°œê²¬ëœ ì´ìŠˆ: {summary.get('issue_count', 0)}ê°œ

ğŸ’¼ íˆ¬ì ë¶„ì„ í˜„í™©:
â€¢ ê¸°ë³¸ë¶„ì„ (45%): ì¬ë¬´ì œí‘œ ê¸°ë°˜ ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ì¹´ë“œ
â€¢ ê¸°ìˆ ë¶„ì„ (30%): ì°¨íŠ¸ íŒ¨í„´ ë° ê¸°ìˆ ì  ì§€í‘œ 
â€¢ ê°ì •ë¶„ì„ (25%): ë‰´ìŠ¤ ë° ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„

ğŸ“ˆ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì´ë©°, 50-60ëŒ€ íˆ¬ììë¥¼ ìœ„í•œ 
   ë§ì¶¤í˜• ë¶„ì„ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.

ğŸŒ ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.
"""
            
        except Exception as e:
            logger.error(f"ì¼ì¼ ìš”ì•½ ì´ë©”ì¼ í¬ë§· ì‹¤íŒ¨: {e}")
            return f"ì¼ì¼ ìš”ì•½ í¬ë§· ì˜¤ë¥˜: {str(e)}"
    
    def _send_email(self, subject: str, body: str, attachments: List[str] = None) -> bool:
        """ì´ë©”ì¼ ì „ì†¡"""
        if not self.email_enabled:
            logger.warning("ğŸ“§ ì´ë©”ì¼ ì„¤ì •ì´ ì—†ì–´ ì•Œë¦¼ì„ ì „ì†¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            msg = MimeMultipart()
            msg['From'] = self.email_user
            msg['To'] = ', '.join(self.alert_recipients)
            msg['Subject'] = subject
            
            msg.attach(MimeText(body, 'plain', 'utf-8'))
            
            # ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬
            if attachments:
                for file_path in attachments:
                    if Path(file_path).exists():
                        with open(file_path, 'rb') as attachment:
                            part = MimeBase('application', 'octet-stream')
                            part.set_payload(attachment.read())
                        
                        encoders.encode_base64(part)
                        part.add_header(
                            'Content-Disposition',
                            f'attachment; filename= {Path(file_path).name}'
                        )
                        msg.attach(part)
            
            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
                server.starttls()
                server.login(self.email_user, self.email_password)
                server.send_message(msg)
            
            logger.debug(f"ğŸ“§ ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ: {subject}")
            return True
            
        except Exception as e:
            logger.error(f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ë°±ì—…')
    parser.add_argument('--action', choices=['monitor', 'backup', 'restore', 'cleanup', 'list'], 
                       default='monitor', help='ì‹¤í–‰í•  ì‘ì—…')
    parser.add_argument('--backup-type', choices=['daily', 'weekly'], 
                       default='daily', help='ë°±ì—… ìœ í˜•')
    parser.add_argument('--backup-file', help='ë³µì›í•  ë°±ì—… íŒŒì¼')
    parser.add_argument('--target-db', help='ë³µì› ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤')
    parser.add_argument('--keep-days', type=int, default=30, help='ë°±ì—… ë³´ê´€ ì¼ìˆ˜')
    parser.add_argument('--send-email', action='store_true', help='ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        if args.action == 'monitor':
            print("ğŸ” ì›ŒëŸ° ë²„í• ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            monitor = DataMonitor()
            health_report = monitor.generate_health_report()
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: {health_report['system_status']}")
            print(f"ğŸ“… ì²´í¬ ì‹œê°„: {health_report['timestamp']}")
            
            if 'summary' in health_report:
                summary = health_report['summary']
                print(f"\nğŸ’¼ ì‹œìŠ¤í…œ ìš”ì•½:")
                print(f"  â€¢ ğŸ“ˆ ì´ ìƒì¥ê¸°ì—…: {summary.get('total_companies', 0):,}ê°œ")
                print(f"  â€¢ ğŸ† ì›ŒëŸ° ë²„í• ìŠ¤ì½”ì–´ ì ìš©: {summary.get('buffett_scored', 0):,}ê°œ")
                print(f"  â€¢ ğŸ“Š í‰ê·  ë²„í• ì ìˆ˜: {summary.get('avg_buffett_score', 0):.1f}/110ì ")
                print(f"  â€¢ ğŸ¯ ì‹œìŠ¤í…œ ê±´ê°•ë„: {summary.get('health_score', 0)}/100ì ")
            
            if health_report.get('issues'):
                print(f"\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œ ({len(health_report['issues'])}ê°œ):")
                for issue in health_report['issues']:
                    print(f"  {issue}")
            
            if health_report.get('recommendations'):
                print(f"\nğŸ’¡ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ ({len(health_report['recommendations'])}ê°œ):")
                for rec in health_report['recommendations']:
                    print(f"  {rec}")
            
            # ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡
            if args.send_email:
                alert_manager = AlertManager()
                alert_manager.send_health_alert(health_report)
                if health_report['system_status'] in ['excellent', 'good']:
                    alert_manager.send_daily_summary(health_report)
            
        elif args.action == 'backup':
            print(f"ğŸ’¾ {args.backup_type} ë°±ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            backup_manager = DataBackupManager()
            backup_results = backup_manager.create_backup(args.backup_type)
            
            if 'error' not in backup_results:
                successful = [db for db, result in backup_results.items() if not result.startswith('error')]
                failed = [db for db, result in backup_results.items() if result.startswith('error')]
                
                print(f"âœ… ë°±ì—… ì™„ë£Œ: {len(successful)}/{len(backup_results)}ê°œ ì„±ê³µ")
                for db_name in successful:
                    print(f"  â€¢ {db_name}: {Path(backup_results[db_name]).name}")
                
                if failed:
                    print(f"\nâŒ ë°±ì—… ì‹¤íŒ¨:")
                    for db_name in failed:
                        print(f"  â€¢ {db_name}: {backup_results[db_name]}")
                
                # ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡
                if args.send_email:
                    alert_manager = AlertManager()
                    alert_manager.send_backup_notification(backup_results)
            else:
                print(f"âŒ ë°±ì—… ì‹¤íŒ¨: {backup_results['error']}")
        
        elif args.action == 'restore':
            if not args.backup_file or not args.target_db:
                print("âŒ ë³µì›ì—ëŠ” --backup-fileê³¼ --target-dbê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            
            print(f"ğŸ”„ ë°±ì—… ë³µì›: {args.backup_file} -> {args.target_db}")
            
            backup_manager = DataBackupManager()
            success = backup_manager.restore_backup(args.backup_file, args.target_db)
            
            if success:
                print("âœ… ë³µì› ì™„ë£Œ!")
            else:
                print("âŒ ë³µì› ì‹¤íŒ¨!")
        
        elif args.action == 'cleanup':
            print(f"ğŸ§¹ {args.keep_days}ì¼ ì´ìƒëœ ë°±ì—…ì„ ì •ë¦¬í•©ë‹ˆë‹¤...")
            
            backup_manager = DataBackupManager()
            deleted_count = backup_manager.cleanup_old_backups(args.keep_days)
            
            print(f"âœ… {deleted_count}ê°œ ë°±ì—… íŒŒì¼ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
            
        elif args.action == 'list':
            print("ğŸ“‹ ë°±ì—… íŒŒì¼ ëª©ë¡:")
            
            backup_manager = DataBackupManager()
            backups = backup_manager.list_backups()
            
            if backups:
                print(f"\n{'íŒŒì¼ëª…':<40} {'ë°ì´í„°ë² ì´ìŠ¤':<10} {'í¬ê¸°(MB)':<10} {'ìƒì„±ì¼ì‹œ':<20}")
                print("-" * 85)
                for backup in backups:
                    print(f"{backup['filename']:<40} {backup['database']:<10} {backup['size_mb']:<10} {backup['created']:<20}")
            else:
                print("ë°±ì—… íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return True
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)